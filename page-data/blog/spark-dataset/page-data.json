{"componentChunkName":"component---src-templates-blog-js","path":"/blog/spark-dataset","result":{"data":{"markdownRemark":{"frontmatter":{"title":"Datasets and DataFrames","date":"2019-03-03"},"html":"<h2>Describing Spark SQL</h2>\n<p>Unlike the basic Spark <code class=\"language-text\">RDD</code> API, the Spark SQL API provides additional data structures used for holding data and performing computations. As a result, Spark SQL is able to perform improved optimizations. Specifically, Spark SQL is used for executing SQL queries. Spark SQL can also be used to read data from an existing Hive installation. When running SQL from within another programming language, the results are returned as a <code class=\"language-text\">Dataset</code> or <code class=\"language-text\">DataFrame</code>.</p>\n<h2>Datasets and DataFrames</h2>\n<p>Similar to an <code class=\"language-text\">RDD</code>, a <code class=\"language-text\">Dataset</code> is a distributed collection of data that can be cached in memory. It provides the following benefits:</p>\n<ul>\n<li>Strong typing</li>\n<li>Ability to use powerful lambda functions</li>\n<li>Optimized execution engine</li>\n</ul>\n<p>A <code class=\"language-text\">DataFrame</code> is a <code class=\"language-text\">Dataset</code> organized into named columns. It is conceptually equivalent to a table in a relational database or a pandas <code class=\"language-text\">DataFrame</code>. However, it has improved internal optimizations. For a more detailed description of the benefits of <code class=\"language-text\">Datasets</code> and <code class=\"language-text\">DataFrames</code>, please refer to this <a href=\"https://databricks.com/blog/2016/07/14/a-tale-of-three-apache-spark-apis-rdds-dataframes-and-datasets.html\" target=\"_blank\" rel=\"nofollow\">article</a>.</p>"}},"pageContext":{"slug":"spark-dataset"}},"staticQueryHashes":["2961437231","3159585216"]}