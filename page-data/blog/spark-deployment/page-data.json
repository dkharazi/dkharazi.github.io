{"componentChunkName":"component---src-templates-blog-js","path":"/blog/spark-deployment","result":{"data":{"markdownRemark":{"frontmatter":{"title":"Spark Deployment Modes","date":"2019-03-28"},"html":"<p>This post provides an overview of the different deployment modes in Spark and how each deployment mode changes the behavior of Spark components. In the coming posts, we'll dive deeper into more low-level concepts. Meaning, we'll explore the Spark internals, along with some examples.</p>\n<p>An application can be deployed to a cluster in one of two modes: <em>cluster</em> or <em>client</em> mode. These modes determine the location of the driver process. By default, Spark will run a driver in an application on the client JVM. Python applications can't run in cluster mode on a standalone cluster.</p>\n<p>To walk through an example demonstrating the interaction between a driver program and cluster components in standalone mode, refer to the <a href=\"/blog/spark-standalone/\">my other post</a>.</p>\n<h2>Client-Deploy Mode</h2>\n<p>As stated previously, the deployment mode determines the location of the driver process. In client-deploy mode, the driver program runs on the client's JVM process. Meaning, the driver program runs on the client's machine. This is the same machine as the one that called the <code class=\"language-text\">spark-submit</code> command, which implies the driver process sits outside of the cluster. Generally, applications deployed in client mode perform the following steps:</p>\n<ol>\n<li>Client's JVM process submits a driver to the master</li>\n<li>The driver is launched</li>\n<li>Master instructs workers to start executor processes for the driver</li>\n<li>Workers launch executor JVMs</li>\n<li>\n<p>The driver and executors communicate independently</p>\n<ul>\n<li>Doesn't involves the master or workers</li>\n</ul>\n</li>\n</ol>\n<p><img src=\"/f4b936a138f19424b9bb26e6b5f5a039/standalone-client.svg\" alt=\"standaloneclient\"></p>\n<h2>Cluster-Deploy Mode</h2>\n<p>In cluster-deploy mode, the driver program runs on its own JVM process located inside the cluster. Indicating, the driver program doesn't run on the client's machine. Instead, it runs on a node within the cluster. Again, the driver program is started by a worker JVM, but runs in a separate JVM in cluster-deploy mode. Generally, applications deployed in cluster mode perform the following steps:</p>\n<ol>\n<li>Client's JVM process submits a driver to the master</li>\n<li>Master instructs one of its workers to launch a driver</li>\n<li>That worker launches a driver JVM in the cluster</li>\n<li>Master instructs any workers to start executors for the driver</li>\n<li>Those workers launch executor JVMs</li>\n<li>\n<p>The driver and executors communicate independently</p>\n<ul>\n<li>Doesn't involves the master and workers</li>\n</ul>\n</li>\n</ol>\n<p><img src=\"/e5cd11d221bdb2be2c917f04bddb8313/standalone-cluster.svg\" alt=\"standalonecluster\"></p>"}},"pageContext":{"slug":"spark-deployment"}},"staticQueryHashes":["2961437231","3159585216"]}