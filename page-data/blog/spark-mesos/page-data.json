{"componentChunkName":"component---src-templates-blog-js","path":"/blog/spark-mesos","result":{"data":{"markdownRemark":{"frontmatter":{"title":"Testing Spark Applications with Mesos","date":"2019-07-04"},"html":"<p>This post walks through an example of running a cluster using a Mesos cluster manager on Mac OS. In the coming posts, we'll explore other examples, including clusters running a <a href=\"/blog/spark-standalone/\">standalone</a> cluster manager and a cluster manager in <a href=\"/blog/spark-yarn/\">YARN</a>.</p>\n<h2>Table of Contents</h2>\n<ul>\n<li><a href=\"#describing-the-mesos-architecture\">Describing the Mesos Architecutre</a></li>\n<li><a href=\"#comparing-mesos-and-standalone-architectures\">Comparing Mesos and Standalone Architectures</a></li>\n<li><a href=\"#setting-up-mesos\">Setting up Mesos</a></li>\n<li><a href=\"#setting-up-a-sparksession\">Setting up a SparkSession</a></li>\n<li><a href=\"#launching-mesos-daemons\">Launching Mesos Daemons</a></li>\n<li><a href=\"#launching-spark-daemons\">Launching Spark Daemons</a></li>\n<li><a href=\"#accessing-web-ui-for-daemons\">Accessing Web UI for Daemons</a></li>\n<li><a href=\"#launching-applications-in-client-mode\">Launching Applications in Client Mode</a></li>\n</ul>\n<h2>Describing the Mesos Architecture</h2>\n<p>The Mesos architecture is arguably more similar to the standalone architecture, compared to the YARN architecture. This is because the essential components of the Mesos architecture include a master and workers only. In the Mesos architecture, a master schedules worker resources for applications that need to use them. Then, workers launch executors for applications, which execute tasks.</p>\n<p>Mesos can run Docker containers. As a result, Mesos essentially can run any application that can be set up in a Docker container, which includes Spark applications.</p>\n<p>Generally, Mesos is more powerful than a cluster with a Spark standalone cluster manager. Mesos can be used for applications other than Spark, as well. Specifically, it can be used for Java, Scala, Python, and other applications. It can also do more than schedule CPU and RAM resources. In particular, it is capable of scheduling disk space, network ports, etc.</p>\n<p>Spark applications running on Mesos consist of two components. These two components include a scheduler and executor. The scheduler accepts or rejects CPU and RAM resources offered by the Mesos master. Then, this master automatically starts Mesos workers, which automatically start executors. Lastly, Mesos executors run tasks as requested by the scheduler.</p>\n<h2>Comparing Mesos and Standalone Architectures</h2>\n<p>Resource scheduling is the most distinct difference between the Mesos and standalone architectures. Specifically, a standalone cluster manager <em>automatically</em> assigns resources to applications. A Mesos cluster manager <em>optionally</em> offers resources to applications. In this case, an application can accept and refuse the resources.</p>\n<h2>Setting up Mesos</h2>\n<ol>\n<li>\n<p>Install Mesos</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token operator\">$ </span>brew <span class=\"token function\">install</span> mesos</code></pre></div>\n</li>\n<li>\n<p>Install the ZooKeeper dependency</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token operator\">$ </span>brew <span class=\"token function\">install</span> zookeeper</code></pre></div>\n</li>\n<li>\n<p>Optionally, assign IP addresses for masters in <code class=\"language-text\">/etc/mesos/zk</code>:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">zk://192.0.2.1:2181,192.0.2.2:2181/mesos</code></pre></div>\n</li>\n</ol>\n<h2>Setting up a SparkSession</h2>\n<ol>\n<li>Download <a href=\"https://apache.claz.org/spark/spark-2.4.6/spark-2.4.6-bin-hadoop2.7.tgz\" target=\"_blank\" rel=\"nofollow\">Spark 2.4.6</a></li>\n<li>Add the path for Spark in <code class=\"language-text\">.bash_profile</code>:</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">export SPARK_HOME=./spark-2.4.6-bin-hadoop2.7</code></pre></div>\n<ol start=\"3\">\n<li>Create the file <code class=\"language-text\">./conf/spark-defaults.conf</code>:</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">spark.master=yarn\nspark.driver.am.memory=512m\nspark.yarn.am.memory=512m\nspark.executor.memory=512m\nspark.eventLog.enabled=true\nspark.eventLog.dir=./tmp/spark-events/\nspark.history.fs.logDirectory=./tmp/spark-events/\nspark.driver.memory=5g</code></pre></div>\n<ol start=\"4\">\n<li>Create a Spark application:</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># test.py</span>\n<span class=\"token operator\">>></span><span class=\"token operator\">></span> <span class=\"token keyword\">from</span> pyspark <span class=\"token keyword\">import</span> SparkContext\n<span class=\"token operator\">>></span><span class=\"token operator\">></span> <span class=\"token builtin\">file</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"~/data.txt\"</span>  <span class=\"token comment\"># path of data</span>\n<span class=\"token operator\">>></span><span class=\"token operator\">></span> masterurl <span class=\"token operator\">=</span> <span class=\"token string\">'spark://localhost:7077'</span>\n<span class=\"token operator\">>></span><span class=\"token operator\">></span> sc <span class=\"token operator\">=</span> SparkContext<span class=\"token punctuation\">(</span>masterurl<span class=\"token punctuation\">,</span> <span class=\"token string\">'myapp'</span><span class=\"token punctuation\">)</span>\n<span class=\"token operator\">>></span><span class=\"token operator\">></span> data <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>textFile<span class=\"token punctuation\">(</span><span class=\"token builtin\">file</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>cache<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token operator\">>></span><span class=\"token operator\">></span> num_a <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span><span class=\"token builtin\">filter</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> s<span class=\"token punctuation\">:</span> <span class=\"token string\">'a'</span> <span class=\"token keyword\">in</span> s<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>count<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token operator\">>></span><span class=\"token operator\">></span> <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>num_a<span class=\"token punctuation\">)</span>\n<span class=\"token operator\">>></span><span class=\"token operator\">></span> sc<span class=\"token punctuation\">.</span>stop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2>Launching Mesos Daemons</h2>\n<ol>\n<li>\n<p>Start the master:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token operator\">$ </span><span class=\"token function\">sudo</span> <span class=\"token function\">service</span> mesos-master start</code></pre></div>\n</li>\n<li>\n<p>Start a worker:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token operator\">$ </span><span class=\"token function\">sudo</span> <span class=\"token function\">service</span> mesos-slave start</code></pre></div>\n</li>\n<li>\n<p>Stop the master:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token operator\">$ </span><span class=\"token function\">sudo</span> <span class=\"token function\">service</span> mesos-master stop</code></pre></div>\n</li>\n<li>\n<p>Stop a worker:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token operator\">$ </span><span class=\"token function\">sudo</span> <span class=\"token function\">service</span> mesos-slave stop</code></pre></div>\n</li>\n</ol>\n<h2>Launching Spark Daemons</h2>\n<ol>\n<li>\n<p>Start a master daemon in standalone mode</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token operator\">$ </span>./sbin/start-master.sh</code></pre></div>\n</li>\n<li>\n<p>Start a worker daemon</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token operator\">$ </span>./sbin/start-slave.sh spark://localhost:7077</code></pre></div>\n</li>\n<li>\n<p>Start a history daemon</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token operator\">$ </span>./sbin/start-history-server.sh</code></pre></div>\n</li>\n<li>\n<p>Start a Spark application</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token operator\">$ </span>./bin/spark-submit <span class=\"token punctuation\">\\</span>\n--master mesos://localhost:5050 <span class=\"token punctuation\">\\</span>\ntest.py</code></pre></div>\n</li>\n<li>\n<p>Stop the daemons</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token operator\">$ </span>./sbin/stop-master.sh\n$ ./sbin/stop-slave.sh\n$ ./sbin/stop-history-server.sh</code></pre></div>\n</li>\n</ol>\n<h2>Accessing Web UI for Daemons</h2>\n<p>Mesos provides a web UI for each initialized daemon. By default, Spark creates a web UI for the master on port <code class=\"language-text\">5050</code>. The workers can take on different ports and can be accessed via the master web UI. The history server can be accessed on port <code class=\"language-text\">18080</code> by default. The table below summarizes the default locations for each web UI.</p>\n<table>\n<thead>\n<tr>\n<th>Daemon</th>\n<th>Port</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Mesos Master</td>\n<td><code class=\"language-text\">5050</code></td>\n</tr>\n<tr>\n<td>Spark History</td>\n<td><code class=\"language-text\">18080</code></td>\n</tr>\n</tbody>\n</table>\n<h2>Launching Applications in Client Mode</h2>\n<ol>\n<li>Mesos workers offer their resources to the master</li>\n<li>\n<p>The Mesos scheduler registers with the Mesos master</p>\n<ul>\n<li>The Mesos master is located in the cluster</li>\n<li>The Mesos scheduler is Spark's Mesos-specific scheduler</li>\n<li>The Mesos scheduler runs in the driver</li>\n</ul>\n</li>\n<li>\n<p>The Mesos master offers available resources to the Mesos scheduler</p>\n<ul>\n<li>This happens continuously</li>\n<li>The offer is sent out every second while master is alive</li>\n</ul>\n</li>\n<li>The Mesos scheduler accepts some of the resources</li>\n<li>\n<p>The Mesos scheduler sends metadata about the resources to the Mesos master</p>\n<ul>\n<li>This metadata includes information about these resources and tasks that run these resources</li>\n</ul>\n</li>\n<li>The Mesos master asks the workers to start the tasks with its specified resources</li>\n<li>The Mesos workers launch Mesos executors</li>\n<li>The Mesos executors launch Spark executors consisting of Tasks</li>\n<li>The Spark executors communicate with the Spark driver</li>\n</ol>\n<p><img src=\"/ba2baf777014cc5fa9fcf0f80c6fffbc/mesos-client.svg\" alt=\"MesosClient\"></p>"}},"pageContext":{"slug":"spark-mesos"}},"staticQueryHashes":["2961437231","3159585216"]}