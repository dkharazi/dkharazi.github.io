{"componentChunkName":"component---src-templates-blog-js","path":"/blog/spark-yarn","result":{"data":{"markdownRemark":{"frontmatter":{"title":"Testing Spark Applications with YARN","date":"2019-06-17"},"html":"<p>This post walks through an example of running a cluster using a YARN cluster manager on Mac OS. In the coming posts, we'll explore other examples, including clusters running a <a href=\"/blog/spark-standalone/\">standalone</a> cluster manager and <a href=\"/blog/spark-mesos/\">Mesos</a> cluster manager.</p>\n<h2>Table of Contents</h2>\n<ul>\n<li><a href=\"#describing-the-yarn-architecture\">Describing the YARN Architecutre</a></li>\n<li><a href=\"#comparing-yarn-and-standalone-architectures\">Comparing YARN and Standalone Architecture</a></li>\n<li><a href=\"#setting-up-hadoop\">Setting up Hadoop</a></li>\n<li><a href=\"#setting-up-a-sparksession\">Setting up a SparkSession</a></li>\n<li><a href=\"#launching-yarn-daemons\">Launching YARN Daemons</a></li>\n<li><a href=\"#launching-spark-daemons\">Launching Spark Daemons</a></li>\n<li><a href=\"#accessing-web-ui-for-daemons\">Accessing Web UI for Daemons</a></li>\n<li><a href=\"#launching-applications-in-client-mode\">Launching Applications in Client Mode</a></li>\n<li><a href=\"#launching-applications-in-cluster-mode\">Launching Applications in Cluster Mode</a></li>\n</ul>\n<h2>Describing the YARN Architecture</h2>\n<p>There are many redundancies found throughout the standard YARN architecture compared to the standalone architecture in Spark. There are a few additional components in YARN that replaces some of the daemons in the standalone architecture:</p>\n<ul>\n<li>Resource Manager</li>\n<li>Node Manager</li>\n<li>Containers</li>\n<li>Application Master</li>\n</ul>\n<p>Essentially, the resource manager is the same as the master process in Spark's standalone mode. The node manager is essentially the same as the worker process. There is a single resource manager per cluster and a single node manager per node in the cluster. </p>\n<p>Rather than representing executors and processes as JVM instances, YARN represents them as containers. However, each containers is still run as a JVM with a requested heap size. These containers contain an application master, which is responsible for requesting application resources from the resource manager.</p>\n<p>When an application is run using YARN, the driver process acts as the YARN application master in Spark. Then, node managers monitor CPU and RAM resources used by containers. As a result, they report these resources to the resource manager.</p>\n<h2>Comparing YARN and Standalone Architectures</h2>\n<p>Although a the standalone Spark cluster manager and the YARN cluster manager has a lot of similarities, some of the responsibilities change and JVM instances behave differently. Primarily, resource scheduling is performed by the master JVM in standalone mode, whereas it is performed by the resource manager in YARN.</p>\n<p>Executors are asked to start by the master JVM in standalone mode, whereas they are asked to start by the application master in YARN. Job scheduling still is performed by the Spark scheduler in both modes. When Spark is running on YARN, the Spark driver process acts as the YARN application master. Additionally, YARN refers to its processes as containers, rather than JVM instances in standalone mode.</p>\n<h2>Setting up Hadoop</h2>\n<ol>\n<li>Install Hadoop:</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token operator\">$ </span>brew <span class=\"token function\">install</span> hadoop</code></pre></div>\n<ol start=\"2\">\n<li>Download Java version supported by Hadoop 3.0:</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token operator\">$ </span>brew cask <span class=\"token function\">install</span> java8</code></pre></div>\n<ol start=\"3\">\n<li>Configure the path of Java ran by Hadoop:</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"># /usr/local/Cellar/hadoop/3.2.1_1/libexec/etc/hadoop-env.sh\nexport JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_231.jdk/Contents/Home</code></pre></div>\n<ol start=\"4\">\n<li>Configure the HDFS address:</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"xml\"><pre class=\"language-xml\"><code class=\"language-xml\"><span class=\"token comment\">&lt;!--/usr/local/Cellar/hadoop/3.2.1_1/libexec/etc/core-site.xml--></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>configuration</span><span class=\"token punctuation\">></span></span>\n  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>property</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>\n      hadoop.tmp.dir\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>value</span><span class=\"token punctuation\">></span></span>\n      /usr/local/Cellar/hadoop/hdfs/tmp\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>value</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>description</span><span class=\"token punctuation\">></span></span>\n      A base for other temporary directories\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>description</span><span class=\"token punctuation\">></span></span>             \n  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>property</span><span class=\"token punctuation\">></span></span>\n  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>property</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>\n      fs.default.name\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>value</span><span class=\"token punctuation\">></span></span>\n      hdfs://localhost:8020\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>value</span><span class=\"token punctuation\">></span></span>\n  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>property</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>configuration</span><span class=\"token punctuation\">></span></span></code></pre></div>\n<ol start=\"5\">\n<li>Configure the MapReduce JobTracker address:</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"xml\"><pre class=\"language-xml\"><code class=\"language-xml\"><span class=\"token comment\">&lt;!--/usr/local/Cellar/hadoop/3.2.1_1/libexec/etc/mapred-site.xml--></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>configuration</span><span class=\"token punctuation\">></span></span>\n  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>property</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>\n      mapred.job.tracker\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>value</span><span class=\"token punctuation\">></span></span>\n      localhost:8021\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>value</span><span class=\"token punctuation\">></span></span>\n  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>property</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>configuration</span><span class=\"token punctuation\">></span></span></code></pre></div>\n<ol start=\"6\">\n<li>Configure the HDFS properties:</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"xml\"><pre class=\"language-xml\"><code class=\"language-xml\"><span class=\"token comment\">&lt;!--/usr/local/Cellar/hadoop/3.2.1_1/libexec/etc/hdfs-site.xml--></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>configuration</span><span class=\"token punctuation\">></span></span>\n  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>property</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>\n      dfs.replication\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>value</span><span class=\"token punctuation\">></span></span>\n      1\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>value</span><span class=\"token punctuation\">></span></span>\n  <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>property</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>configuration</span><span class=\"token punctuation\">></span></span></code></pre></div>\n<ol start=\"7\">\n<li>Configure SHH Keys:</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token operator\">$ </span>ssh-keygen -t rsa -P <span class=\"token string\">''</span> -f ~/.ssh/id_rsa\n$ <span class=\"token function\">cat</span> ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys\n$ <span class=\"token function\">chmod</span> 0600 ~/.ssh/authorized_keys</code></pre></div>\n<h2>Setting up a SparkSession</h2>\n<ol>\n<li>Download <a href=\"https://apache.claz.org/spark/spark-2.4.6/spark-2.4.6-bin-hadoop2.7.tgz\" target=\"_blank\" rel=\"nofollow\">Spark 2.4.6</a></li>\n<li>Add the path for Spark in <code class=\"language-text\">.bash_profile</code>:</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">export SPARK_HOME=./spark-2.4.6-bin-hadoop2.7</code></pre></div>\n<ol start=\"3\">\n<li>Create the file <code class=\"language-text\">./conf/spark-defaults.conf</code>:</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">spark.master=yarn\nspark.driver.am.memory=512m\nspark.yarn.am.memory=512m\nspark.executor.memory=512m\nspark.eventLog.enabled=true\nspark.eventLog.dir=./tmp/spark-events/\nspark.history.fs.logDirectory=./tmp/spark-events/\nspark.driver.memory=5g</code></pre></div>\n<ol start=\"4\">\n<li>Create a Spark application:</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># test.py</span>\n<span class=\"token operator\">>></span><span class=\"token operator\">></span> <span class=\"token keyword\">from</span> pyspark <span class=\"token keyword\">import</span> SparkContext\n<span class=\"token operator\">>></span><span class=\"token operator\">></span> <span class=\"token builtin\">file</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"~/data.txt\"</span>  <span class=\"token comment\"># path of data</span>\n<span class=\"token operator\">>></span><span class=\"token operator\">></span> masterurl <span class=\"token operator\">=</span> <span class=\"token string\">'spark://localhost:7077'</span>\n<span class=\"token operator\">>></span><span class=\"token operator\">></span> sc <span class=\"token operator\">=</span> SparkContext<span class=\"token punctuation\">(</span>masterurl<span class=\"token punctuation\">,</span> <span class=\"token string\">'myapp'</span><span class=\"token punctuation\">)</span>\n<span class=\"token operator\">>></span><span class=\"token operator\">></span> data <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>textFile<span class=\"token punctuation\">(</span><span class=\"token builtin\">file</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>cache<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token operator\">>></span><span class=\"token operator\">></span> num_a <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span><span class=\"token builtin\">filter</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> s<span class=\"token punctuation\">:</span> <span class=\"token string\">'a'</span> <span class=\"token keyword\">in</span> s<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>count<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token operator\">>></span><span class=\"token operator\">></span> <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>num_a<span class=\"token punctuation\">)</span>\n<span class=\"token operator\">>></span><span class=\"token operator\">></span> sc<span class=\"token punctuation\">.</span>stop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2>Launching YARN Daemons</h2>\n<ol>\n<li>\n<p>Start YARN from the NameNode:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token operator\">$ </span>./bin/start-yarn.sh</code></pre></div>\n</li>\n</ol>\n<p>The YARN cluster manager needs to be started on the NameNode. By doing this, the ResourceManager and NodeManagers should be started using the command above. Specifically, we should see the following lines after running the command above.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Starting resourcemanager\nStarting nodemanagers</code></pre></div>\n<ol start=\"2\">\n<li>\n<p>Stop the daemons</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token operator\">$ </span>./bin/stop-yarn.sh</code></pre></div>\n</li>\n</ol>\n<h2>Launching Spark Daemons</h2>\n<ol>\n<li>\n<p>Start a master daemon in standalone mode</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token operator\">$ </span>./sbin/start-master.sh</code></pre></div>\n</li>\n<li>\n<p>Start a worker daemon</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token operator\">$ </span>./sbin/start-slave.sh spark://localhost:7077</code></pre></div>\n</li>\n<li>\n<p>Start a history daemon</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token operator\">$ </span>./sbin/start-history-server.sh</code></pre></div>\n</li>\n<li>\n<p>Start a Spark application</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token operator\">$ </span>./bin/spark-submit <span class=\"token punctuation\">\\</span>\n--master <span class=\"token function\">yarn</span> <span class=\"token punctuation\">\\</span>\ntest.py</code></pre></div>\n</li>\n<li>\n<p>Stop the daemons</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token operator\">$ </span>./sbin/stop-master.sh\n$ ./sbin/stop-slave.sh\n$ ./sbin/stop-history-server.sh</code></pre></div>\n</li>\n</ol>\n<h2>Accessing Web UI for Daemons</h2>\n<p>Spark provides a web UI for each initialized daemon. By default, Spark creates a web UI for the master on port <code class=\"language-text\">8080</code>. The workers can take on different portsand can be accessed via the master web UI. The history server can be accessed on port <code class=\"language-text\">18080</code> by default. The table below summarizes the default locations for each web UI.</p>\n<table>\n<thead>\n<tr>\n<th>Daemon</th>\n<th>Port</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>YARN Master</td>\n<td><code class=\"language-text\">8080</code></td>\n</tr>\n<tr>\n<td>YARN Worker</td>\n<td><code class=\"language-text\">8081</code></td>\n</tr>\n<tr>\n<td>Spark History</td>\n<td><code class=\"language-text\">18080</code></td>\n</tr>\n<tr>\n<td>HDFS Resource Manager</td>\n<td><code class=\"language-text\">9870</code></td>\n</tr>\n<tr>\n<td>YARN JobTracker</td>\n<td><code class=\"language-text\">8088</code></td>\n</tr>\n</tbody>\n</table>\n<h2>Launching Applications in Client Mode</h2>\n<ol>\n<li>Client's JVM process submits a driver to the resource manager</li>\n<li>The driver is launched</li>\n<li>\n<p>The resource manager instructs a node manager to start a container with an application master</p>\n<ul>\n<li>The container includes the application master</li>\n<li>The resource manager represents the master</li>\n<li>The node manager represents the worker</li>\n<li>The application master requests for resources</li>\n</ul>\n</li>\n<li>Node manager launches a container with an application master</li>\n<li>Application master requests the resource manager to allocate resources for the application</li>\n<li>App master asks node managers to start executor containers</li>\n<li>\n<p>Node managers launch executors</p>\n<ul>\n<li>This is on behalf of the Spark application master</li>\n</ul>\n</li>\n<li>\n<p>The driver and executors communicate independently</p>\n<ul>\n<li>Doesn't involves the master or workers</li>\n</ul>\n</li>\n</ol>\n<p><img src=\"/fa40e4b908ccfcea54f0e62ad42c1688/yarn-client.svg\" alt=\"ClientModeYARN\"></p>\n<h2>Launching Applications in Cluster Mode</h2>\n<ol>\n<li>Client's JVM process submits a driver to the resource manager</li>\n<li>\n<p>The resource manager instructs a node manager to start a container with an application master</p>\n<ul>\n<li>The container includes the application master</li>\n<li>The resource manager represents the master</li>\n<li>The node manager represents the worker</li>\n<li>The application master requests for resources</li>\n</ul>\n</li>\n<li>\n<p>Node manager launches a container with an application master</p>\n<ul>\n<li>The application master contains the spark driver</li>\n</ul>\n</li>\n<li>Application master requests the resource manager to allocate resources for the application</li>\n<li>App master asks node managers to start executor containers</li>\n<li>\n<p>Node managers launch executors</p>\n<ul>\n<li>This is on behalf of the Spark application master</li>\n</ul>\n</li>\n<li>\n<p>The driver and executors communicate independently</p>\n<ul>\n<li>Doesn't involves the master or workers</li>\n</ul>\n</li>\n</ol>\n<p><img src=\"/54b031f131be5adf52293f1de3c6c813/yarn-cluster.svg\" alt=\"ClusterModeYARN\"></p>"}},"pageContext":{"slug":"spark-yarn"}},"staticQueryHashes":["2961437231","3159585216"]}