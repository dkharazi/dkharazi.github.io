{"componentChunkName":"component---src-templates-entry-js","path":"/notes/de/etl/hdfs","result":{"data":{"markdownRemark":{"frontmatter":{"title":"Hadoop HDFS"},"html":"<h3>Describing Distributed File Systems</h3>\n<ul>\n<li>A file system is a system of files used for storage</li>\n<li>\n<p>A distributed file system is any file system that:</p>\n<ul>\n<li>Provides access of files from multiple hosts</li>\n<li>Provides access of files via a computer network</li>\n</ul>\n</li>\n<li>A distributed file system is managed locally or remotely</li>\n</ul>\n<h3>Differentiating between File Systems and Databases</h3>\n<ul>\n<li>A file system stores unstructured, unrelated data</li>\n<li>Databases store structured, related data</li>\n<li>Databases have more overhead compared to file systems</li>\n<li>File systems tend to be more lightweight</li>\n<li>This is because they aren't structured</li>\n<li>Implying, they don't have as much overhead</li>\n<li>\n<p>On the other hand, databases have the following overhead:</p>\n<ul>\n<li>Schemas</li>\n<li>Built-in operations for indexing, searching, etc.</li>\n</ul>\n</li>\n<li>Data files in databases are formatted in its own way</li>\n<li>This provides querying capabilities and other operations specific to some system</li>\n<li>The data files in a file system are formatted in its original, raw format</li>\n</ul>\n<h3>Examples of Locally Managed DFS</h3>\n<ul>\n<li>HDFS</li>\n<li>Ceph</li>\n<li>Lustre</li>\n</ul>\n<h3>Examples of Remotely Managed DFS</h3>\n<ul>\n<li>HDFS</li>\n<li>AWS S3</li>\n<li>GCS</li>\n<li>Microsoft Azure</li>\n</ul>\n<h3>Defining HDFS</h3>\n<ul>\n<li>HDFS is a component of the Hadoop ecosystem</li>\n<li>HDFS assumes that a file can't be changed once its written</li>\n<li>HDFS can be used as a standalone DFS</li>\n<li>Meaning, we can plug in different computing engines into HDFS</li>\n<li>For example, we can use Spark or MapReduce as a computing engine</li>\n<li>Then, we can use HDFS as our storage</li>\n<li>\n<p>HDFS has the following benefits:</p>\n<ul>\n<li>Designed to run on commodity hardware</li>\n<li>Is highly fault-tolerant</li>\n<li>Designed to be deployed on cheaper hardware</li>\n<li>Provides high throughput access to application data</li>\n<li>Suitable for applications with large datasets</li>\n</ul>\n</li>\n</ul>\n<h3>Defining the Goals of HDFS</h3>\n<ul>\n<li>Handles hardware failure</li>\n<li>Provides streaming access to datasets</li>\n<li>Handles very large datasets</li>\n<li>Portable from one platform to another platform</li>\n<li>\n<p>Executes code on the machine on which the data is stored</p>\n<ul>\n<li>Meaning, we don't need to load data on the machine where the code lives</li>\n<li>Moving small code to the machine with large processing capacity makes sense</li>\n</ul>\n</li>\n</ul>\n<h3>References</h3>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Comparison_of_distributed_file_systems\" target=\"_blank\" rel=\"nofollow\">Wiki of Distributed File Systems</a></li>\n<li><a href=\"https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html\" target=\"_blank\" rel=\"nofollow\">Design of HDFS</a></li>\n<li><a href=\"https://stackoverflow.com/a/40602021/12777044\" target=\"_blank\" rel=\"nofollow\">Moving Data in HDFS</a></li>\n<li><a href=\"https://www.researchgate.net/figure/Apache-Hadoop-Ecosystem_fig3_307619823\" target=\"_blank\" rel=\"nofollow\">Defining the Hadoop Ecosystem</a></li>\n</ul>"}},"pageContext":{"slug":"de/etl/hdfs","previousSlug":"de/etl/elt","nextSlug":"de/etl/hdfs_architecture","previousTitle":"ETL and ELT","nextTitle":"HDFS Architecture"}},"staticQueryHashes":[]}