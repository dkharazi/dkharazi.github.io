{"componentChunkName":"component---src-templates-entry-js","path":"/notes/de/etl/mapreduce","result":{"data":{"markdownRemark":{"frontmatter":{"title":"MapReduce"},"html":"<h3>Describing Hadoop MapReduce</h3>\n<ul>\n<li>MapReduce is a component of the Hadoop ecosystem</li>\n<li>It is a software framework</li>\n<li>It is used for processing vast amounts of data</li>\n<li>\n<p>It ensures data is processed:</p>\n<ul>\n<li>In a distributed manner</li>\n<li>In parallel</li>\n<li>On large clusters</li>\n<li>Using cheap hardware</li>\n<li>Reliably</li>\n<li>In a fault-tolerant manner</li>\n</ul>\n</li>\n</ul>\n<h3>Distributed Computing with MapReduce</h3>\n<ul>\n<li>\n<p>MapReduce is consists of two functions:</p>\n<ul>\n<li>A <code class=\"language-text\">map</code> function</li>\n<li>A <code class=\"language-text\">reduce</code> function</li>\n</ul>\n</li>\n<li>\n<p>In Hadoop:</p>\n<ul>\n<li>MapReduce is a distributed computing framework</li>\n<li>HDFS is a distributed storage framework</li>\n</ul>\n</li>\n<li>As a result, the <code class=\"language-text\">map</code> and <code class=\"language-text\">reduce</code> functions run on many different computers</li>\n</ul>\n<h3>Defining the MapReduce Algorithm</h3>\n<ol>\n<li>\n<p>A <code class=\"language-text\">map</code> function</p>\n<ul>\n<li>Takes in data from each <code class=\"language-text\">DataNode</code> as input</li>\n<li>\n<p>Outputs key-value pairs</p>\n<ul>\n<li>A key is a piece of data from the <code class=\"language-text\">DataNode</code></li>\n<li>A value is an aggregation from the <code class=\"language-text\">DataNode</code></li>\n</ul>\n</li>\n<li>Each value only measures an aggregation of an individual <code class=\"language-text\">DataNode</code></li>\n</ul>\n</li>\n<li>\n<p>A <code class=\"language-text\">reduce</code> function</p>\n<ul>\n<li>Takes in key-value pairs for each <code class=\"language-text\">DataNode</code></li>\n<li>\n<p>Outputs updated key-value pairs from all <code class=\"language-text\">DataNodes</code></p>\n<ul>\n<li>A key is a piece of data from all <code class=\"language-text\">DataNodes</code></li>\n<li>A value is an aggregation from all <code class=\"language-text\">DataNodes</code></li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<h3>Illustrating MapReduce by Counting Words</h3>\n<p><img src=\"/b2ff1b7b06d94c1e0579efc6169f8506/mapreduce.png\" alt=\"mapreduce\"></p>\n<h3>Describing Components of MapReduce Implementation</h3>\n<ul>\n<li>\n<p>A MapReduce application consists of two main services:</p>\n<ul>\n<li>One <code class=\"language-text\">JobTracker</code></li>\n<li>Some <code class=\"language-text\">TaskTrackers</code></li>\n</ul>\n</li>\n<li>\n<p>A <code class=\"language-text\">JobTracker</code> has the following properties:</p>\n<ul>\n<li>It acts like a master-server</li>\n<li>It communicates with the <code class=\"language-text\">NameNode</code></li>\n<li>It ensures the execution of submitted jobs is completed</li>\n</ul>\n</li>\n<li>\n<p>A <code class=\"language-text\">TaskTracker</code> has the following properties:</p>\n<ul>\n<li>It communicates with the <code class=\"language-text\">DataNodes</code></li>\n<li>It is responsible for performing the actual service</li>\n<li>Meaning, it performs mapping, shuffling, and reducing tasks</li>\n</ul>\n</li>\n</ul>\n<h3>Defining the MapReduce Workflow</h3>\n<ol>\n<li>\n<p>Client submits an application to the <code class=\"language-text\">JobTracker</code></p>\n<ul>\n<li>The <code class=\"language-text\">JobTracker</code> separates the application into tasks</li>\n<li>These tasks include the <code class=\"language-text\">map</code>, <code class=\"language-text\">reduce</code>, <code class=\"language-text\">shuffle</code> functions</li>\n</ul>\n</li>\n<li>\n<p>That <code class=\"language-text\">JobTracker</code> requests metadata from its <code class=\"language-text\">NameNode</code></p>\n<ul>\n<li>This metadata includes the location of relevant data</li>\n</ul>\n</li>\n<li>\n<p>The <code class=\"language-text\">NameNode</code> provides the <code class=\"language-text\">JobTracker</code> with metadata</p>\n<ul>\n<li>This metadata has data about the location of <code class=\"language-text\">DataNodes</code></li>\n<li>Only the <code class=\"language-text\">DataNodes</code> with any relevant data are included</li>\n</ul>\n</li>\n<li>\n<p>The <code class=\"language-text\">JobTracker</code> locates available <code class=\"language-text\">TaskTrackers</code></p>\n<ul>\n<li>\n<p>It tries to find <code class=\"language-text\">TaskTrackers</code> that are:</p>\n<ul>\n<li>Available</li>\n<li>Closest to the relevant <code class=\"language-text\">DataNodes</code> as possible</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>The <code class=\"language-text\">JobTracker</code> submits its tasks to the <code class=\"language-text\">TaskTrackers</code></p>\n<ul>\n<li>Only the chosen <code class=\"language-text\">TaskTrackers</code> are included</li>\n</ul>\n</li>\n<li>\n<p>The <code class=\"language-text\">TaskTrackers</code> execute any individual tasks</p>\n<ul>\n<li>They communicate with their specified <code class=\"language-text\">DataNodes</code></li>\n<li><code class=\"language-text\">TaskTrackers</code> send progress reports to the <code class=\"language-text\">JobTracker</code></li>\n<li>They do this by sending heartbeat signals</li>\n<li>If the <code class=\"language-text\">JobTracker</code> doesn't receive a heartbeat signal, it will assume the <code class=\"language-text\">TaskTracker</code> has failed</li>\n<li>Then, it will reschedule its task and start a new <code class=\"language-text\">TaskTracker</code></li>\n</ul>\n</li>\n<li>\n<p>The <code class=\"language-text\">TaskTrackers</code> complete all individual tasks</p>\n<ul>\n<li>They update the <code class=\"language-text\">JobTracker</code></li>\n</ul>\n</li>\n<li>\n<p>The <code class=\"language-text\">JobTracker</code> updates its status to <em>complete</em></p>\n<ul>\n<li>Client applications can poll the <code class=\"language-text\">JobTracker</code> for information now</li>\n</ul>\n</li>\n</ol>\n<h3>References</h3>\n<ul>\n<li><a href=\"https://hadoop.apache.org/docs/r1.2.1/mapred_tutorial.html\" target=\"_blank\" rel=\"nofollow\">Hadoop MapReduce Documentation</a></li>\n<li><a href=\"https://www.guru99.com/introduction-to-mapreduce.html\" target=\"_blank\" rel=\"nofollow\">Introduction to Hadoop MapReduce</a></li>\n<li><a href=\"https://www.slideshare.net/cloudera/introduction-to-yarn-and-mapreduce-2\" target=\"_blank\" rel=\"nofollow\">Slides on MapReduce and Yarn</a></li>\n<li><a href=\"https://www.reddit.com/r/explainlikeimfive/comments/r3mdn/eli5_mapreduce_and_hadoop/\" target=\"_blank\" rel=\"nofollow\">An ELI5 Post Hadoop MapReduce</a></li>\n<li><a href=\"https://www.edureka.co/blog/mapreduce-tutorial/#usecase\" target=\"_blank\" rel=\"nofollow\">MapReduce Course for Use Cases</a></li>\n</ul>"}},"pageContext":{"slug":"de/etl/mapreduce","previousSlug":"de/etl/hbase","nextSlug":"de/etl/yarn","previousTitle":"HBase","nextTitle":"YARN"}},"staticQueryHashes":[]}