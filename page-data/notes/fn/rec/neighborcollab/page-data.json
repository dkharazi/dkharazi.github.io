{"componentChunkName":"component---src-templates-entry-js","path":"/notes/fn/rec/neighborcollab","result":{"data":{"markdownRemark":{"frontmatter":{"title":"Neighborhood-Based Collab Filtering"},"html":"<h3>Introducing Recommendation Systems</h3>\n<ul>\n<li>\n<p>The goal of any recommender system is to do the following:</p>\n<ul>\n<li>Predict the ratings that a certain user would give to different catalog items</li>\n<li>Create a list of recommendations by selecting</li>\n<li>Rank those items with the highest predicted ratings</li>\n</ul>\n</li>\n<li>Collaborative filtering is used for creating recommendation systems</li>\n</ul>\n<h3>Introducing Collaborative Filtering</h3>\n<ul>\n<li>Under the hood, collaborative filtering uses a predictive model to predict a rating for a given pair of user and item</li>\n<li>These predictions are based on how similar users rate similar items</li>\n<li>Specifically, the model captures interactions between known users and items from the rating matrix</li>\n<li>The benefit of collaborative filtering is that they're capable of making recommendations based only on the patterns and similarities available in the rating matrix</li>\n<li>\n<p>It has the following disadvantages:</p>\n<ul>\n<li>Difficult to build reliable rating predictions if matrix is too sparse</li>\n<li>Difficult to handle new users or items (cold start problem)</li>\n<li>Somewhat biased towards popular items (difficult to pick up on unusual tastes)</li>\n</ul>\n</li>\n</ul>\n<h3>Defining Types of Collaborative Filtering</h3>\n<ul>\n<li>\n<p>Collaborative filtering algorithms are usually categorized into two subgroups:</p>\n<ul>\n<li>Neighborhood-based methods</li>\n<li>Model-based methods</li>\n</ul>\n</li>\n<li>\n<p>Neighborhood-based methods predict unknown ratings for a given user or item by doing the following:</p>\n<ul>\n<li>Finding the most similar known users or items</li>\n<li>Averaging ratings from their records</li>\n</ul>\n</li>\n<li>\n<p>Model-based methods go beyond the nearest neighbor approach</p>\n<ul>\n<li>Specifically, they use more sophisticated, predictive models</li>\n</ul>\n</li>\n</ul>\n<h3>Introducing Neighborhood-Based Collab Filtering</h3>\n<ul>\n<li>Neighborhood-based collaborative filtering relies on a similarity measure between users or items</li>\n<li>\n<p>Neighborhood-based collaborative filtering include the following steps:</p>\n<ul>\n<li>Optionally predicting missing ratings in the ratings matrix</li>\n<li>Creating a similarity matrix</li>\n<li>Selecting <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span> similar users or items that should be included in the neighborhood</li>\n<li>\n<p>Predicting ratings by averaging neighbors' ratings</p>\n<ul>\n<li>This average is based on the values of the <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span> nearest neighbors</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>Collaborative filtering can be mixed with neighborhood-based, content-based, and model-based recommendation methods</p>\n<ul>\n<li>For example, one can perform a model-based method for initializing missing ratings (e.g. naive bayes model)</li>\n<li>Or, one can perform a neighborhood-based method for initializing missing ratings (e.g. <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span> nearest neighbors)</li>\n<li>Then, compute Pearson similarities between users or items based on this complete rating matrix</li>\n<li>Lastly, make actual recommendations using neighborhood-based or model-based algorithms</li>\n</ul>\n</li>\n</ul>\n<h3>Describing Neighborhood-Based Collaborative Filtering</h3>\n<ul>\n<li>\n<p>The following are some popular similarity measures:</p>\n<ul>\n<li>Pearson's correlation coefficient</li>\n<li>Euclidean distance</li>\n<li>Cosine similarity value</li>\n<li>Discounted similarity value</li>\n<li>Inverse user frequency</li>\n</ul>\n</li>\n<li>\n<p>The following are some popular mean-centering formulas:</p>\n<ul>\n<li>Baseline-centering</li>\n<li>Amplification</li>\n<li>Neighborhood selection</li>\n</ul>\n</li>\n<li>Specifically, these similarity values measures the similarity of ratings between two users or two items</li>\n<li>\n<p>These two cases are known as the following:</p>\n<ul>\n<li>User-based similarity</li>\n<li>Item-based similarity</li>\n</ul>\n</li>\n</ul>\n<h3>Disadvantages of Neighborhood-Based Filtering</h3>\n<ul>\n<li>\n<p>Has a narrow view of the problem</p>\n<ul>\n<li>Focuses only on the <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span> nearest neighbors</li>\n</ul>\n</li>\n<li>\n<p>Sometimes performance decreases on sparse data</p>\n<ul>\n<li>Where, items/users have few common ratings</li>\n</ul>\n</li>\n<li>\n<p>Relies on pairwise instance comparison and defers the computation of the\nrecommendations until it is requested</p>\n<ul>\n<li>This makes it challenging to split the computation between offline and online phases</li>\n</ul>\n</li>\n</ul>\n<h3>Introducing Used-Based and Item-Based Filtering</h3>\n<ul>\n<li>\n<p>The goal of user-based similarity is to find similar users:</p>\n<ul>\n<li>Then, we can recommend items with similar ratings from these similar users</li>\n<li>For example, a user-based approach can recommend items that have not been rated by the given user, but have been positively rated by at least some neighborhood users</li>\n</ul>\n</li>\n<li>\n<p>The goal of item-based similarity is to find similar items:</p>\n<ul>\n<li>Then, we can recommend items with similar ratings for the given user</li>\n<li>For example, a user who positively rated a few items in the past will probably like items that are rated similarly to these past choices by many other users</li>\n</ul>\n</li>\n<li>\n<p>The user-based and item-based approaches are structurally similar</p>\n<ul>\n<li>They can use different measures</li>\n<li>There are many different variants of similarity and rating averaging formulas for each approach</li>\n</ul>\n</li>\n</ul>\n<h3>Illustrating User-Based Collaborative Filtering</h3>\n<ul>\n<li>\n<p>Used-based collaborative filtering uses two key functions:</p>\n<ul>\n<li>A similarity measure for users</li>\n<li>A rating averaging formula</li>\n</ul>\n</li>\n<li>Suppose we had <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>4</mn></mrow><annotation encoding=\"application/x-tex\">4</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">4</span></span></span></span> customers interested in product discovery</li>\n<li>Our first step would include computing a similarity matrix</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>User 1</th>\n<th>User 2</th>\n<th>User 3</th>\n<th>User 4</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>User 1</td>\n<td>1.00</td>\n<td>0.87</td>\n<td>0.94</td>\n<td>-0.79</td>\n</tr>\n<tr>\n<td>User 2</td>\n<td>0.87</td>\n<td>1.00</td>\n<td>0.87</td>\n<td>-0.84</td>\n</tr>\n<tr>\n<td>User 3</td>\n<td>0.94</td>\n<td>0.87</td>\n<td>1.00</td>\n<td>-0.93</td>\n</tr>\n<tr>\n<td>User 4</td>\n<td>-0.79</td>\n<td>-0.84</td>\n<td>-0.93</td>\n<td>1.00</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>Notice, the first three users are positively correlated with each other</li>\n<li>\n<p>This similarity matrix allows us to look up a neighborhood of the top <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span> most similar\nusers for a given target user</p>\n<ul>\n<li>Then, mix their ratings to make a prediction</li>\n</ul>\n</li>\n<li>Thus, we'll perform a rating averaging formula over the users</li>\n<li>Lastly, we'll predict the missing ratings for products of a user using KNN regression</li>\n</ul>\n<h3>Describing Challenges of User-Based Filtering</h3>\n<ul>\n<li>\n<p>In practice, user-based recommendation methods can face scalability challenges</p>\n<ul>\n<li>Especially, as the number of system users approaches tens and hundreds of millions</li>\n<li>If the neighborhoods are computed in advance, the amount of computations will be large</li>\n</ul>\n</li>\n<li>\n<p>In addition, the target user profile might not be available in advance</p>\n<ul>\n<li>E.g. the browsing history within the current web session</li>\n<li>One possible way to work around this limitation is to switch from user similarities to item similarities</li>\n</ul>\n</li>\n</ul>\n<h3>Illustrating Item-Based Collaborative Filtering</h3>\n<ul>\n<li>Our first step would include computing a similarity matrix</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Movie 1</th>\n<th>Movie 2</th>\n<th>Movie 3</th>\n<th>Movie 4</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Movie 1</td>\n<td>1.00</td>\n<td>0.87</td>\n<td>0.94</td>\n<td>-0.79</td>\n</tr>\n<tr>\n<td>Movie 2</td>\n<td>0.87</td>\n<td>1.00</td>\n<td>0.87</td>\n<td>-0.84</td>\n</tr>\n<tr>\n<td>Movie 3</td>\n<td>0.94</td>\n<td>0.87</td>\n<td>1.00</td>\n<td>-0.93</td>\n</tr>\n<tr>\n<td>Movie 4</td>\n<td>-0.79</td>\n<td>-0.84</td>\n<td>-0.93</td>\n<td>1.00</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>Notice, the first three movies are positively correlated with each other</li>\n<li>\n<p>This similarity matrix allows us to look up a neighborhood of the top <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span> most similar\nmovies for a given target movie</p>\n<ul>\n<li>Then, mix their ratings to make a prediction</li>\n</ul>\n</li>\n<li>Thus, we'll perform a rating averaging formula over the movies</li>\n<li>Lastly, we'll predict the missing ratings for movies of a user using KNN regression</li>\n</ul>\n<h3>Illustrating Differences in User- and Item-Based Filtering</h3>\n<ul>\n<li>\n<p>To reiterate, the goal of user-based recommendations is to generate recommendations based on similar users, whereas the goal of item-based recommendations is to generate recommendations based on similar items</p>\n<ul>\n<li>As an example, suppose we have a Spotify rating matrix where users refer to listeners and items refer to songs</li>\n<li>In this example, suppose I'm receiving a recommendation when my favorite genres are country and jazz</li>\n<li>\n<p>An item-based recommender would return recommended songs based on other similar songs</p>\n<ul>\n<li>As a result, I may be recommended a song that is similar to other country songs I like</li>\n<li>Or, I may be recommended a song that is similar to other jazz songs I like</li>\n<li>Thus, I'll eventually receive a mix of recommended jazz and country songs over time</li>\n</ul>\n</li>\n<li>\n<p>A user-based recommender would return recommended songs based on other similar listeners</p>\n<ul>\n<li>As a result, I may be recommended a song that other listeners liked who also enjoy country and jazz</li>\n<li>Thus, I'll eventually receive a mix of recommended jazz and country songs over time</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>Notice, user-based and item-based are structurally similar</p>\n<ul>\n<li>The only difference is the nature of their similarity measure</li>\n<li>As a result, we should expect the recommendations to be somewhat similar between the two</li>\n<li>To find the right one for our needs, we'll likely need to do some experimentation</li>\n</ul>\n</li>\n</ul>\n<h3>Comparing User-Based and Item-Based Filtering</h3>\n<ul>\n<li>Since the item-based similarity matrix is comparatively much smaller, item-based approaches are typially more scalable</li>\n<li>User-based approaches capture certain relationships that might not be recognized by\nitem-based methods</li>\n<li>The ratio between the number of users and items is useful if we're wanting to use one over the other</li>\n<li>However, some advanced recommendation methods combine item-based and user-based models to take advantage of both methods</li>\n</ul>\n<h3>References</h3>\n<ul>\n<li><a href=\"https://www.cs.cmu.edu/~mgormley/courses/10601-s17/slides/lecture25-mf.pdf\" target=\"_blank\" rel=\"nofollow\">Slides for Latent Factor Models</a></li>\n<li><a href=\"https://spark.apache.org/docs/2.2.0/ml-collaborative-filtering.html\" target=\"_blank\" rel=\"nofollow\">Alternating Least Squares with Spark</a></li>\n<li><a href=\"https://towardsdatascience.com/building-a-collaborative-filtering-recommender-system-with-clickstream-data-dffc86c8c65\" target=\"_blank\" rel=\"nofollow\">Collaborative Filtering with Implicit Feedback</a></li>\n<li><a href=\"https://algorithmicweb.files.wordpress.com/2018/07/algorithmic-marketing-ai-for-marketing-operations-r1-7g.pdf\" target=\"_blank\" rel=\"nofollow\">Textbook about Algorithmic Marketing</a></li>\n<li><a href=\"https://databricks.com/blog/2020/12/18/personalizing-the-customer-experience-with-recommendations.html\" target=\"_blank\" rel=\"nofollow\">Personalizing Experience with Callaborative Filtering</a></li>\n<li><a href=\"https://realpython.com/build-recommendation-engine-collaborative-filtering/\" target=\"_blank\" rel=\"nofollow\">Building Recommendation Systems in Python</a></li>\n<li><a href=\"http://cs229.stanford.edu/proj2007/Dommeti-NeighborhoodBasedMethodsForCollaborativeFiltering.pdf\" target=\"_blank\" rel=\"nofollow\">Paper about Collaborative Filtering Methods</a></li>\n<li><a href=\"https://developers.google.com/machine-learning/recommendation/collaborative/basics\" target=\"_blank\" rel=\"nofollow\">Google Course about Basics of Collaborative Fitlering</a></li>\n</ul>"}},"pageContext":{"slug":"fn/rec/neighborcollab","previousSlug":"fn/rec/content","nextSlug":"fn/rec/modelcollab","previousTitle":"Content-Based Filtering","nextTitle":"Model-Based Collab Filtering"}},"staticQueryHashes":[]}