{"componentChunkName":"component---src-templates-entry-js","path":"/notes/ml/basic_statistics/sampling","result":{"data":{"markdownRemark":{"frontmatter":{"title":"Sampling"},"html":"<h3>Motivating Sampling</h3>\n<ul>\n<li>We assume that whatever it is that gave us our data is well-modeled by some\nrandom process</li>\n<li>In effect, each time we make a measurement, we ask the process to spit out numbers according to some population distribution, and we then sample the distribution</li>\n<li>We think of sampling as closing our eyes and picking a data point out of a box, we call the set of all data-points in the box the population</li>\n<li>We assume that the true distribution is unknown and lies behind our data</li>\n<li>If we want to learn about that distribution from the data, then we need to know something about the kind of data it is likely to give us</li>\n<li>That is, we need to know the sampling distribution, or the distribution of data values given that the true distribution takes a certain functional form</li>\n<li>More specifically, we need to know the sampling distribution with certain parameter values</li>\n<li>Then, we can sample from it in a specified way</li>\n</ul>\n<h3>The Notion of a Statistic</h3>\n<ul>\n<li>Naturally, we want to summarize our data so we can ignore as much about our data as possible</li>\n<li>For example, we would most likely prefer to have a summary of our data, rather than having to remember the exact sequence of heads and tails for a million coin-tosses</li>\n<li>A summary of the data is called a <em>statistic</em></li>\n<li>\n<p>More formally, any function of the data is a statistic, provided the following:</p>\n<ul>\n<li>The function of the data is well-defined for any number of data-points</li>\n<li>The function of the data doesn't have any random inputs other than the data</li>\n</ul>\n</li>\n</ul>\n<h3>Loss of Variability Under Sampling</h3>\n<ul>\n<li>Itâ€™s generally true that, whatever measure of variability we pick, its value in a sample will tend to be smaller than its population value (since the sample variance is a biased estimator of the population variance)</li>\n<li>For example (as an extreme case), there is no variation in our data if our sample consists of a single point</li>\n<li>Generally, sampling a subset from the population is unlikely to give an exactly representative sample</li>\n<li>Naturally, the more probable events will tend to show up in the sample more often</li>\n</ul>\n<h3>Monte Carlo Methods</h3>\n<ul>\n<li>\n<p>Even if we know the exact population distribution, determining the sampling distribution can be difficult for the following reasons:</p>\n<ul>\n<li>Sometimes we don't have a nice, readily-available (or closed-form) probability density function</li>\n<li>Getting an accurate sample from the population can become difficult (especially as the range of values increases)</li>\n<li>Getting a large enough sample can become difficult (especially if our rejection regions are large)</li>\n</ul>\n</li>\n<li>\n<p>In these situations, we have three options:</p>\n<ol>\n<li>Manually try to gather and test a sample ourselves</li>\n<li>\n<p>Turn to the literature in the hopes that somebody else has already sampled from the population distribution we are looking for, so we can use their sample</p>\n<ol start=\"3\">\n<li>Simulate ourselves</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>In certain situation, the first two options can save us a lot of time if the sample is readily available to us</li>\n<li>Typically, however, the first two options will lead to barriers, causing a great deal of time to be wasted on researching and manual effort</li>\n<li>\n<p>The third option (i.e. simulation) can be tricky, but could save us a lot of time (and lead us to accurate estimates) if:</p>\n<ul>\n<li>We know what sampling procedure to use (i.e. MCMC, Gibbs, etc.)</li>\n<li>We know the population distribution</li>\n<li>We have a good source of random variables</li>\n</ul>\n</li>\n<li>If we simulate many samples, then the law of large numbers tells us the empirical frequencies of our simulations will approach to the actual sampling distribution</li>\n<li>This process is called Monte Carlo simultion (or Monte Carlo method)</li>\n<li>We typically don't know how many times we should run our simulation before we can become confident that we are close to the right distribution</li>\n<li>Sometimes, a few hundred points is enough, but other times we need hundreds of thousands (or more) of points</li>\n</ul>\n<h3>References</h3>\n<ul>\n<li><a href=\"http://bactra.org/prob-notes/srl.pdf\" target=\"_blank\" rel=\"nofollow\">Probability, Statistics and Stochastic Processes</a></li>\n<li><a href=\"https://www.quora.com/Why-is-it-hard-to-directly-sample-from-certain-statistical-distributions\" target=\"_blank\" rel=\"nofollow\">Why Sampling is Hard</a></li>\n</ul>"}},"pageContext":{"slug":"ml/basic_statistics/sampling","previousSlug":"ml/basic_statistics/correlation","nextSlug":"ml/basic_statistics/estimation","previousTitle":"Correlation","nextTitle":"Estimation"}},"staticQueryHashes":[]}