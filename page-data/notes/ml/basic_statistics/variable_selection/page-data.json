{"componentChunkName":"component---src-templates-entry-js","path":"/notes/ml/basic_statistics/variable_selection","result":{"data":{"markdownRemark":{"frontmatter":{"title":"Variable Selection"},"html":"<h3>Describing Variable Selection Methods</h3>\n<ul>\n<li>Variable selection refers to selecting which variables to include in our model</li>\n<li>Therefore, it is a special case of model selection</li>\n<li>People tend to use variable selection when the competing models differ on which variables should be included, but agree on the mathematical form that will be used for each variable</li>\n<li>For example, a <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mtext>Temperature</mtext></mrow><annotation encoding=\"application/x-tex\">\\text{Temperature}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord text\"><span class=\"mord\">Temperature</span></span></span></span></span> predictor variable may or may not be included as a predictor, but there is no conversation about whether we'd use <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mtext>Temperature</mtext></mrow><annotation encoding=\"application/x-tex\">\\text{Temperature}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord text\"><span class=\"mord\">Temperature</span></span></span></span></span>, <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mtext>Temperature</mtext><mn>2</mn></msup></mrow><annotation encoding=\"application/x-tex\">\\text{Temperature}^2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.081778em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord text\"><span class=\"mord\">Temperature</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.887338em;\"><span style=\"top:-3.1362300000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span></span>, or <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>log</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mtext>Temperature</mtext><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\log(\\text{Temperature})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mopen\">(</span><span class=\"mord text\"><span class=\"mord\">Temperature</span></span><span class=\"mclose\">)</span></span></span></span></li>\n</ul>\n<h3>Avoiding p-values During Variable Selection</h3>\n<ul>\n<li>It is very tempting (and common) to use p-values to select variables</li>\n<li>In other words, we sometimes fall into the trap of believing significant variables get included in our model and insignificant variables do not get included- Specifically, we fall into the trap of believing variables with smaller p-values are higher priorities to include than ones with smaller p-values</li>\n<li>Using p-values for variable selection, or to find the most significant variables, is typically a bad idea</li>\n</ul>\n<h3>Why p-values Should Not be Used for Variable Selection</h3>\n<ul>\n<li>\n<p>P-values should not be used for variable selection because p-values measure the following:</p>\n<ul>\n<li>\n<p>Large (or small) sample size</p>\n<ul>\n<li>Increasing the sample size will increase all of the test statistics and make every variable more significant</li>\n<li>This is because of the <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">n</span></span></span></span> in the denominator</li>\n<li>In other words, the p-value will also be a measure of our sample size</li>\n</ul>\n</li>\n<li>\n<p>Larger coefficients</p>\n<ul>\n<li>Large coefficients will, all else being equal, have larger test statistics and be more significant</li>\n<li>This is because of the <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>β</mi></mrow><annotation encoding=\"application/x-tex\">\\beta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span></span></span></span> in the numerator</li>\n</ul>\n</li>\n<li>\n<p>Reducing the noise in our predictions</p>\n<ul>\n<li>Reducing the noise around the regression line will increase all of the test statistics and make every variable more significant</li>\n<li>This is because of the <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>σ</mi></mrow><annotation encoding=\"application/x-tex\">\\sigma</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span></span></span></span> in the denominator</li>\n</ul>\n</li>\n<li>\n<p>Increasing the variance in our predictors</p>\n<ul>\n<li>Increasing the variance in a predictor variable will, all else being equal, increase the test statistic and make the variable more significant</li>\n<li>This is because of the Var(<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">X</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span></span></span></span>) in the denominator</li>\n</ul>\n</li>\n<li>\n<p>Increasing correlation between predictor variables</p>\n<ul>\n<li>More correlation between <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>X</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">X_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> and the other predictor variables will, all else being equal, decrease the test statistic and make the variable less significant</li>\n<li>This is because of the <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi><mi>I</mi><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">VIF</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span></span></span></span> in the denominator</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3>Final Remarks on p-values</h3>\n<ul>\n<li>The test statistic (and thus p-value) represents an estimate of the actual size of the coefficient with how well we can measure that particular coefficient</li>\n<li>These p-values answer the following question:\n- Can we reliably detect that this coefficient isn't exactly zero?</li>\n<li>These p-values (or F-tests for that matter) do not answer the following questions:\n- Is this variable truly relevant to the response variable?\n- Does including this variable help us predict the response?</li>\n</ul>\n<h3>Better Methods of Variable Selection</h3>\n<ul>\n<li>The cp statistic (or Mallow's statistic) and AIC attempt to estimate how well the model will predict new data</li>\n<li>Cross-validation estimates how well the model will predict new data (by predicting new data data)</li>\n<li>Sometimes, we confuse variable selection with determining how well the model will predict new data</li>\n<li>Therefore, we typically want to use cross-validation and calculate mallow's cp statistic or AIC to measure how well the model will predict new data</li>\n</ul>\n<h3>More on Cross-Validation</h3>\n<ul>\n<li>The standard inferential statistics are only valid if the model is chosen independent of the data being used to calculate them</li>\n<li>If there is any sort of data-dependent model selection (i.e. stepwise variable selection), they are no longer valid</li>\n<li>Therefore, we should split the data into training and testing groups (at random), and use one part to do model selection and the other half to do inference on the selected model</li>\n</ul>\n<h3>References</h3>\n<ul>\n<li><a href=\"http://www.stat.cmu.edu/~cshalizi/TALR/TALR.pdf\" target=\"_blank\" rel=\"nofollow\">Truth about Linear Regression</a></li>\n</ul>"}},"pageContext":{"slug":"ml/basic_statistics/variable_selection","previousSlug":"ml/basic_statistics/bootstrap","nextSlug":"ml/basic_statistics/regression_metrics","previousTitle":"Bootstrap","nextTitle":"Regression Metrics"}},"staticQueryHashes":[]}