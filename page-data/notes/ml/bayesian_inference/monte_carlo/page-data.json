{"componentChunkName":"component---src-templates-entry-js","path":"/notes/ml/bayesian_inference/monte_carlo","result":{"data":{"markdownRemark":{"frontmatter":{"title":"Monte Carlo Simulation"},"html":"<h3>Motivating Sampling</h3>\n<ul>\n<li>\n<p>We always want to know some property related to our population</p>\n<ul>\n<li>Maybe the distribution of our population</li>\n<li>Maybe the expected value of our population</li>\n<li>Maybe the variance of our population</li>\n<li>Maybe the probability of observing a certain value in our population</li>\n</ul>\n</li>\n<li>Unfortunately, our population is infinitely large and/or unknown most of the time</li>\n<li>To solve this problem, we estimate our population</li>\n<li>Estimation is the process of using sampling to calculate guesses of population properties</li>\n<li>Sampling is the process of collecting observations</li>\n<li>A sampling distribution is a distribution represented by our data</li>\n<li>The goal of sampling is to collect data that will give us the best guess of some population property of interest</li>\n<li>In order to find the best guess, we need to collect data that most-closely represents our population</li>\n</ul>\n<h3>Motivating the Monte Carlo Method</h3>\n<ul>\n<li>If we want to calculate the probability of an observation, then we typically compute integrals by finding antiderivatives of a closed form density function</li>\n<li>\n<p>Density functions are deterministic functions</p>\n<ul>\n<li>Specifically, we will always receive the same probability after inputting our parameters and observtion, since the parameters are assumed to be fixed</li>\n</ul>\n</li>\n<li>Although we like to think that probabilities are generated by a single deterministic function in principle, it is sometimes more accurate to think that probabilties are generated from a probabilistic function</li>\n<li>\n<p>For example, our deterministic probability function may not use the most accurate fixed parameters (i.e. mean and variance), which leads to inaccurate probability estimates</p>\n<ul>\n<li>This can especially happen when our sample size is small</li>\n<li>In this case, our parameter estimates will most likely always lead to poor probability estimates, since our methods for parameter estimation are deterministic (i.e. MLE)</li>\n<li>Since an element of randomness is included in probabilistic methods of parameter estimation, our parameter estimates have a higher chance of being more accurate compared to using deterministic methods</li>\n</ul>\n</li>\n<li>The Monte Carlo method is one of the most popular probabilistic methods of estimation</li>\n</ul>\n<h3>Defining the Monte Carlo Algorithm</h3>\n<ul>\n<li>\n<p>Monte Carlo methods generally follow a particular pattern:</p>\n<ol>\n<li>\n<p>Define a domain of possible observations</p>\n<ul>\n<li>For example, let's say we define the random variable <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">X</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span></span></span></span>, which can take on the values <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>1</mn><mo separator=\"true\">,</mo><mn>2</mn><mo separator=\"true\">,</mo><mn>3</mn><mo separator=\"true\">,</mo><mn>4</mn><mo separator=\"true\">,</mo><mn>5</mn><mo separator=\"true\">,</mo><mn>6</mn></mrow><annotation encoding=\"application/x-tex\">1,2,3,4,5,6</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8388800000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">2</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">3</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">4</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">5</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">6</span></span></span></span></li>\n</ul>\n</li>\n<li>\n<p>Randomly generate simulated values from an assumed probability distribution over the domain</p>\n<ul>\n<li>Typically, we decide to simulate from a uniform distribution</li>\n<li>Sometimes, we simulate from normal, beta, bernoulli, and poisson distributions</li>\n<li>Specifically, the more values we simulate, the greater the coverage of our sample space and the more accurate our estimates become</li>\n</ul>\n</li>\n<li>\n<p>Perform a deterministic computation on the simulated values</p>\n<ul>\n<li>For example, we may calculate the probability of observing and even number by calculating the percentage of simulated values that are even to the total number of simulated values</li>\n</ul>\n</li>\n<li>\n<p>Aggregate the results</p>\n<ul>\n<li>For example, we may decide to construct a probability distribution by calculating the probabilities of observing each observation in the sample space</li>\n<li>Or, we may decide to create a credible interval of our parameter estimate</li>\n</ul>\n</li>\n</ol>\n</li>\n</ul>\n<h3>The Law of Large Numbers within the Monte Carlo Method</h3>\n<ul>\n<li>Since Monte Carlo simulation is a probablistic method of calculating probabilities, we don't need to worry about estimating parameters using a deterministic density function</li>\n<li>The Strong Law of Large Numbers is at the core of the Monte Carlo method</li>\n<li>Essentially, the Monte Carlo method is an application of the Law of Large Numbers</li>\n<li>The Monte Carlo method is also referred to as Monte Carlo simulation</li>\n<li>Simulation essentially refers to artificially generating samples from some assumed population distribution</li>\n<li>The Monte Carlo method does not typically involve a random walk algorithm</li>\n<li>The random walk algorithm is typically involved in a markov chain instead</li>\n</ul>\n<h3>Assumptions of Monte Carlo Sampling</h3>\n<ul>\n<li>We assume that we have a proper sampling procedure, such as simple random sampling</li>\n<li>\n<p>We assume that we know the general form of our population distribution</p>\n<ul>\n<li>For example, we may have a good idea that the population distribution follows a normal distribution</li>\n</ul>\n</li>\n<li>\n<p>We assume that we have a good source of random variables</p>\n<ul>\n<li>Specifically, we assume that our sample distribution made up of our sample data (or random variables) closely follows the population distribution</li>\n</ul>\n</li>\n</ul>\n<h3>Summarizing Monte Carlo Sampling</h3>\n<ul>\n<li>Monte Carlo Simulation is a sampling procedure that involves gathering many observations from a population</li>\n<li>The goal of Monte Carlo is to build a sampling distribution that effectively reflects its population distribution</li>\n<li>The Law of Large Numbers makes Monte Carlo Simulation possible</li>\n<li>Specifically, as our sample grows larger, our sampling distribution will resemble our population distribution</li>\n</ul>\n<h3>References</h3>\n<ul>\n<li><a href=\"https://stattrek.com/experiments/simulation.aspx\" target=\"_blank\" rel=\"nofollow\">Basic Simulation Steps</a></li>\n<li><a href=\"http://pdg.lbl.gov/2009/reviews/rpp2009-rev-monte-carlo-techniques.pdf\" target=\"_blank\" rel=\"nofollow\">Paper on Monte Carlo Techniques</a></li>\n<li><a href=\"http://bactra.org/prob-notes/srl.pdf\" target=\"_blank\" rel=\"nofollow\">Probability, Statistics and Stochastic Processes</a></li>\n<li><a href=\"https://pdfs.semanticscholar.org/d99e/754ed8d336cc29bd4342a196cfb1bc69bddb.pdf\" target=\"_blank\" rel=\"nofollow\">Applications of the Law of Large Numbers</a></li>\n<li><a href=\"https://www.palisade.com/risk/monte_carlo_simulation.asp\" target=\"_blank\" rel=\"nofollow\">Use-Cases of Monte Carlo Simulation</a></li>\n<li><a href=\"https://www.quora.com/Is-there-a-reason-to-use-Monte-Carlo-when-we-already-have-a-formula\" target=\"_blank\" rel=\"nofollow\">Motivating Monte Carlo Simulation</a></li>\n<li><a href=\"https://www.stat.cmu.edu/~cshalizi/statcomp/13/lectures/16/lecture-16.pdf\" target=\"_blank\" rel=\"nofollow\">Monte Carlo Simulation Lecture Slides</a></li>\n</ul>"}},"pageContext":{"slug":"ml/bayesian_inference/monte_carlo","previousSlug":"ml/bayesian_inference/probabilistic_model","nextSlug":"ml/bayesian_inference/markov_chain","previousTitle":"Probabilistic Models","nextTitle":"Markov Chains"}},"staticQueryHashes":[]}