{"componentChunkName":"component---src-templates-entry-js","path":"/notes/ml/classification/decision_trees","result":{"data":{"markdownRemark":{"frontmatter":{"title":"Decision Trees"},"html":"<h3>Describing Decision Trees</h3>\n<ul>\n<li>A decision tree is a nonlinear predictive model used for classification</li>\n<li>Regression trees and classification trees are the two types of decision trees</li>\n<li>A decision tree can include a combination of regression tress and classification trees at different levels</li>\n</ul>\n<h3>Motivating Decision Trees</h3>\n<ul>\n<li>Global models refer to a single predictive formula that holds true over an entire data space</li>\n<li>Linear and polynomial regression models are examples of global models</li>\n<li>When the data has lots of features that interact with each other in complicated, nonlinear ways, then assembling a single global model can be very difficult</li>\n<li>Some non-parametric smoothers try to fit models locally and paste them together (i.e. local regression models), but these models are fairly hard to interpret</li>\n<li>Therefore, an alternative approach to nonlinear regression is to partition the space into smaller regions, where the interactions are more manageable</li>\n<li>Then, we partition the sub-divisions again (i.e. recursive partitioning) until we finally get to chunks of the space that are so tame that we can fit simple models to them</li>\n</ul>\n<h3>General Idea of Decision Trees</h3>\n<ol>\n<li>Pick an attribute (e.g. width > 6.5, car = red, etc.)</li>\n<li>Conditioned on a choice, pick another attribute</li>\n<li>In the leaves, assign a class with a majority vote</li>\n<li>Do other branches</li>\n</ol>\n<h3>Representation of Decision Trees</h3>\n<ul>\n<li>A decision tree is a tree represented as either a root node and leaves</li>\n<li>The leaves of a decision tree graphically represent axes that separate classes from each other</li>\n<li>In other words, leaf nodes represent outputs (i.e class assignments)</li>\n<li>Branching is determined by attribute value</li>\n<li>Internal nodes test attributes</li>\n</ul>\n<h3>Classification and Regression Trees</h3>\n<ul>\n<li>A classification tree is a type of decision tree that takes in discrete input and returns discrete output</li>\n<li>A regression tree is a type of decision tree that takes in a continuous input and returns a continuous output</li>\n<li>Leaf values in a classification tree are typically set to the most common value in the training data</li>\n<li>Leaf values in a regression tree are typically set to the mean value in the training data</li>\n<li>In both cases, more compact decision trees typically have more predictive power than decision trees that are very large</li>\n</ul>\n<h3>Learning Decision Trees</h3>\n<ol>\n<li>Resort to a greedy heuristic by starting from an empty decision tree</li>\n<li>Determine the next best attribute to split on by calculating the split with the highest information gain</li>\n<li>Recurse</li>\n</ol>\n<h3>References</h3>\n<ul>\n<li><a href=\"https://www.stat.cmu.edu/~cshalizi/mreg/15/lectures/27/lecture-27.pdf\" target=\"_blank\" rel=\"nofollow\">Classification and Regression Trees</a></li>\n<li><a href=\"https://www.cs.toronto.edu/~urtasun/courses/CSC411_Fall16/06_trees_handout.pdf\" target=\"_blank\" rel=\"nofollow\">Decision Trees Example</a></li>\n</ul>"}},"pageContext":{"slug":"ml/classification/decision_trees","previousSlug":"ml/classification/ensemble","nextSlug":"ml/classification/random_forests","previousTitle":"Ensemble Methods","nextTitle":"Random Forests"}},"staticQueryHashes":[]}