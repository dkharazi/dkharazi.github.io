{"componentChunkName":"component---src-templates-entry-js","path":"/notes/ml/cnn/classic_cnn","result":{"data":{"markdownRemark":{"frontmatter":{"title":"Common Case Studies"},"html":"<h3>Motivating CNN Case Studies</h3>\n<ul>\n<li>To develop a deeper understanding of convolutional neural networks, we should evaluate some popular case studies</li>\n<li>\n<p>The following classical networks are popular case studies:</p>\n<ul>\n<li>LeNet-5</li>\n<li>AlexNet</li>\n<li>VGG-16</li>\n</ul>\n</li>\n<li>More modern convolutional networks are ResNet and Inception</li>\n<li>We've already talked about LeNet-5, so now let's talk about AlexNet and VGG-16</li>\n</ul>\n<h3>Illustrating AlexNet</h3>\n<p><img src=\"/b4e87a19d379e3db4c11aa8811714174/alexnet.svg\" alt=\"alexnet\"></p>\n<h3>Footnotes about AlexNet</h3>\n<ul>\n<li>Similar architecture to LeNet-5</li>\n<li>\n<p>Bigger network compared to LeNet-5</p>\n<ul>\n<li>However, AlexNet is much bigger</li>\n<li>LeNet-5 has about <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>60</mn></mrow><annotation encoding=\"application/x-tex\">60</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">6</span><span class=\"mord\">0</span></span></span></span> thousand parameters</li>\n<li>AlexNet has about <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>60</mn></mrow><annotation encoding=\"application/x-tex\">60</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">6</span><span class=\"mord\">0</span></span></span></span> million parameters</li>\n<li>Meaning, AlexNet is more accurate, but slower to train</li>\n</ul>\n</li>\n<li>\n<p>Uses relu activation functions</p>\n<ul>\n<li>Convolutional layers use relu functions in AlexNet</li>\n<li>Fully-connected layers use relu functions too</li>\n</ul>\n</li>\n<li>\n<p>Trained on multiple GPUs</p>\n<ul>\n<li>When AlexNet was initially created, GPUs were slower</li>\n<li>As a result, AlexNet had a complicated way of training on multiple GPUs</li>\n<li>Specifically, layers were split across separate GPUs</li>\n<li>Then, results were joined back together afterwards</li>\n</ul>\n</li>\n</ul>\n<h3>Illustrating VGG-16</h3>\n<p><img src=\"/40c002a84c36c670d3144b259e25f51c/vgg.svg\" alt=\"vgg-16\"></p>\n<h3>Footnotes about VGG-16</h3>\n<ul>\n<li>\n<p>Simpler architecture compared to AlexNet</p>\n<ul>\n<li>VGG-16 only uses convolutional layers with a <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>3</mn><mo>×</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">3 \\times 3</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord\">3</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">3</span></span></span></span> filter and a stride <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>s</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">s=1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span></li>\n<li>VGG-16 only uses max-pooling layers with a <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>2</mn><mo>×</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">2 \\times 2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">2</span></span></span></span> filter and a stride <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>s</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">s=2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">2</span></span></span></span></li>\n<li>Consequently, VGG-16 uses fewer hyperparameters compared to AlexNet</li>\n</ul>\n</li>\n<li>\n<p>Bigger network compared to AlexNet</p>\n<ul>\n<li>VGG-16 has about <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>138</mn></mrow><annotation encoding=\"application/x-tex\">138</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span><span class=\"mord\">3</span><span class=\"mord\">8</span></span></span></span> million parameters</li>\n<li>Meaning, VGG-16 is more accurate, but slower to train</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3>tldr</h3>\n<ul>\n<li>\n<p>The AlexNet has the following properties:</p>\n<ul>\n<li>Similar architecture to LeNet-5</li>\n<li>Bigger network compared to LeNet-5</li>\n<li>Uses relu activation functions</li>\n<li>Trained on multiple GPUs</li>\n</ul>\n</li>\n<li>\n<p>The VGG-16 has the following properties:</p>\n<ul>\n<li>Bigger network compared to AlexNet</li>\n<li>Simpler architecture compared to AlexNet</li>\n<li>Uses fewer hyperparameters compared to AlexNet</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3>References</h3>\n<ul>\n<li><a href=\"https://www.youtube.com/watch?v=dZVkygnKh1M&#x26;list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF&#x26;index=13\" target=\"_blank\" rel=\"nofollow\">Classic Networks</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=-bvTzZCEOdM&#x26;list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF&#x26;index=12\" target=\"_blank\" rel=\"nofollow\">Convolutional Case Studies</a></li>\n<li><a href=\"https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\" target=\"_blank\" rel=\"nofollow\">AlexNet Paper</a></li>\n<li><a href=\"https://arxiv.org/abs/1409.1556\" target=\"_blank\" rel=\"nofollow\">VGG-16 Paper</a></li>\n<li><a href=\"https://blog.mgechev.com/2018/10/20/transfer-learning-tensorflow-js-data-augmentation-mobile-net/\" target=\"_blank\" rel=\"nofollow\">VGG-16 Illustration</a></li>\n</ul>"}},"pageContext":{"slug":"ml/cnn/classic_cnn","previousSlug":"ml/cnn/fc","nextSlug":"ml/cnn/resnet","previousTitle":"Benefits of Convolution","nextTitle":"Residual Network"}},"staticQueryHashes":[]}