{"componentChunkName":"component---src-templates-entry-js","path":"/notes/ml/cnn/transfer_learning","result":{"data":{"markdownRemark":{"frontmatter":{"title":"Transfer Learning"},"html":"<h3>Motivating Transfer Learning</h3>\n<ul>\n<li>Suppose someone has already trained a network that is relevant to our problem at hand</li>\n<li>\n<p>We may be interested in using the network if:</p>\n<ul>\n<li>The network was trained on very large dataset</li>\n<li>The network provides a very good accuracy</li>\n</ul>\n</li>\n<li>\n<p>By using a popular open-source implementation, we could avoid the following costs:</p>\n<ul>\n<li>\n<p><strong>Expenses</strong></p>\n<ul>\n<li>The training process can require the use of many GPUs</li>\n</ul>\n</li>\n<li>\n<p><strong>Tuning time</strong></p>\n<ul>\n<li>We need to test many sets of hyperparameters that produces the best accuracy</li>\n<li>This process can take months</li>\n</ul>\n</li>\n<li>\n<p><strong>Training time</strong></p>\n<ul>\n<li>We need to compute many weights and biases during forward and backward propagation</li>\n<li>This process can take hours (or days)</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>This process of using an open-source implementation of a deep network is called <em>transfer learning</em></li>\n</ul>\n<h3>Describing Transfer Learning</h3>\n<ul>\n<li>Transfer learning refers to the reuse of a pre-trained model</li>\n<li>Therefore, downloading an open-source implementation will give us its parameters and architecture</li>\n<li>\n<p>From here, we can do the following:</p>\n<ul>\n<li><em>Unfreeze</em> layers to be trained on</li>\n<li>Add or remove layers from the network</li>\n<li>Replace layers with our own layers</li>\n</ul>\n</li>\n<li>\n<p>There are three general approaches to changing layers:</p>\n<ol>\n<li>If we don't have a lot of input data, then we typically freeze our output layer (i.e. softmax) and make adjustments accordingly</li>\n<li>If we have a decent amount of input data, then we can freeze certain layers and train a few others (or remove layers)</li>\n<li>If we have a lot of input data, then we train the entire network while initializing the weights and biases to the ones from our transfer learning model</li>\n</ol>\n</li>\n<li>We should typically prefer to use tranfer learning networks without making many changes</li>\n<li>Unless, we have a very large amount of input data and a large computational budget</li>\n</ul>\n<hr>\n<h3>tldr</h3>\n<ul>\n<li>\n<p>We may be interested in using the network if:</p>\n<ul>\n<li>The network was trained on very large dataset</li>\n<li>The network provides a very good accuracy</li>\n</ul>\n</li>\n<li>\n<p>By using a popular open-source implementation, we could avoid the following costs:</p>\n<ul>\n<li>Expenses</li>\n<li>Tuning time</li>\n<li>Training time</li>\n</ul>\n</li>\n<li>This process of using an open-source implementation of a deep network is called <em>transfer learning</em></li>\n<li>We should typically prefer to use tranfer learning networks without making many changes</li>\n<li>Unless, we have a very large amount of input data and a large computational budget</li>\n</ul>\n<hr>\n<h3>References</h3>\n<ul>\n<li><a href=\"https://www.youtube.com/watch?v=FQM13HkEfBk&#x26;list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF&#x26;index=20\" target=\"_blank\" rel=\"nofollow\">Transfer Learning in Practice</a></li>\n<li><a href=\"https://cs231n.github.io/transfer-learning/\" target=\"_blank\" rel=\"nofollow\">CS231n Transfer Learning</a></li>\n<li><a href=\"https://builtin.com/data-science/transfer-learning\" target=\"_blank\" rel=\"nofollow\">Description of Transfer Learning</a></li>\n</ul>"}},"pageContext":{"slug":"ml/cnn/transfer_learning","previousSlug":"ml/cnn/inception","nextSlug":"ml/cnn/augmentation","previousTitle":"Inception","nextTitle":"Data Augmentation"}},"staticQueryHashes":[]}