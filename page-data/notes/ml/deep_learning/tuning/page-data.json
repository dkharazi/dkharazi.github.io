{"componentChunkName":"component---src-templates-entry-js","path":"/notes/ml/deep_learning/tuning","result":{"data":{"markdownRemark":{"frontmatter":{"title":"The Tuning Process"},"html":"<h3>Motivating the Tuning Process</h3>\n<ul>\n<li>One of the inconveniences of neural networks is tuning hyperparameters</li>\n<li>\n<p>Specifically, we're interested in the following questions:</p>\n<ul>\n<li>What are the most important hyperparameters to tune?</li>\n<li>What range of values should I tune my hyperparameters over?</li>\n<li>How should I organize my tuning process?</li>\n</ul>\n</li>\n</ul>\n<h3>Prioritizing Hyperparameters</h3>\n<ul>\n<li>It is important to tune each hyperparameter</li>\n<li>However, some hyperparameters are more important to tune than other</li>\n<li>\n<p>The following are some common hyperparameters:</p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>α</mi></mrow><annotation encoding=\"application/x-tex\">\\alpha</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span></span>: the learning rate used in our optimization algorithm</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>β</mi><mi>v</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\beta_{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>: used in momentum and adam</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>β</mi><mi>s</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\beta_{s}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">s</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>: used in rmsprop and adam</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding=\"application/x-tex\">\\epsilon</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">ϵ</span></span></span></span>: used in rmsprop and adam</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>l</mi></mrow><annotation encoding=\"application/x-tex\">l</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span></span></span></span>: the number of hidden layers in our network</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">n</span></span></span></span>: the number of hidden units per layer</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>γ</mi></mrow><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05556em;\">γ</span></span></span></span>: the learning rate decay</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span>: the mini-batch size</li>\n</ul>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>Hyperparameter</th>\n<th>Priority</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>α</mi></mrow><annotation encoding=\"application/x-tex\">\\alpha</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span></span></td>\n<td>1</td>\n</tr>\n<tr>\n<td><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">n</span></span></span></span></td>\n<td>2</td>\n</tr>\n<tr>\n<td><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span></td>\n<td>2</td>\n</tr>\n<tr>\n<td><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>β</mi><mi>v</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\beta_{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> for momentum</td>\n<td>2</td>\n</tr>\n<tr>\n<td><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>l</mi></mrow><annotation encoding=\"application/x-tex\">l</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span></span></span></span></td>\n<td>3</td>\n</tr>\n<tr>\n<td><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>γ</mi></mrow><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05556em;\">γ</span></span></span></span></td>\n<td>3</td>\n</tr>\n<tr>\n<td><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>β</mi><mi>v</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\beta_{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> for adam</td>\n<td>4</td>\n</tr>\n<tr>\n<td><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>β</mi><mi>s</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\beta_{s}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">s</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></td>\n<td>4</td>\n</tr>\n<tr>\n<td><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding=\"application/x-tex\">\\epsilon</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">ϵ</span></span></span></span></td>\n<td>4</td>\n</tr>\n</tbody>\n</table>\n<h3>Tip 1: Tune using Random Sampling</h3>\n<ul>\n<li>In the past, hyperparameters used to be tested in a systematic manner that involved looping over a fixed set of hyperparameters</li>\n<li>This technique is called grid search</li>\n<li>Now, hyperparameters are typically tested using random sampling from a hyperparameter space</li>\n<li>This is because grid search only works fine with a small set of hyperparameters</li>\n<li>Visually, the difference in hyperparameters looks like the following:</li>\n</ul>\n<p><img src=\"/d463879662a77a20dbb9e50d9c91602b/tuning.svg\" alt=\"tuning_hyperparameters\"> </p>\n<ul>\n<li>Here, we notice that only <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>5</mn></mrow><annotation encoding=\"application/x-tex\">5</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">5</span></span></span></span> possible values are tested for each hyperparameter in scenario 1</li>\n<li>Specifically, training <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>25</mn></mrow><annotation encoding=\"application/x-tex\">25</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">2</span><span class=\"mord\">5</span></span></span></span> models only gives us information about <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>5</mn></mrow><annotation encoding=\"application/x-tex\">5</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">5</span></span></span></span> possible values for each hyperparameter</li>\n<li>On the other hand, we test <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>25</mn></mrow><annotation encoding=\"application/x-tex\">25</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">2</span><span class=\"mord\">5</span></span></span></span> possible values for each hyperparameter in scenario 2</li>\n<li>Specifically, training <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>25</mn></mrow><annotation encoding=\"application/x-tex\">25</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">2</span><span class=\"mord\">5</span></span></span></span> models only gives us information about <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>25</mn></mrow><annotation encoding=\"application/x-tex\">25</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">2</span><span class=\"mord\">5</span></span></span></span> possible values for each hyperparameter</li>\n</ul>\n<h3>Tip 2: Zooming into Smaller Regions</h3>\n<ul>\n<li>Once our models are finished training, we'll want to evaluate the hyperparameters to see which ones minimized the cost function</li>\n<li>After doing this, we'll typically notice certain regions of hyperparameters working very well</li>\n<li>Therefore, we'll usually focus on that region and sample more densely a second time (or more)</li>\n<li>In other words, we'll keep focusing on a smaller range of hyperparameters after training</li>\n</ul>\n<p><img src=\"/7ca9427cc5593d4193f0aa522970e03f/zoomtuning.svg\" alt=\"zoomtuning\"></p>\n<ul>\n<li>In the above image, the the data points represents combinations of hyperparameters</li>\n<li>A darker data point represents a set of hyperparameters that correspond to a very small cost</li>\n<li>A lighter data point represents a set of hyperparameters that correspond to a very large cost</li>\n<li>We decided that our second window should be be focused around the darker data points, since those sets of parameters tend towards a small cost</li>\n<li>During the second training run, we would focus on this window and observe <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>25</mn></mrow><annotation encoding=\"application/x-tex\">25</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">2</span><span class=\"mord\">5</span></span></span></span> more sets of parameters in this specific regions</li>\n</ul>\n<h3>Scaling Hyperparameters Appropriately</h3>\n<ul>\n<li>Up until now, we've been randomly sampling hyperparameters uniformly on a linear scale</li>\n<li>However, we may want to randomly sample hyperparameters uniformly on a different scale</li>\n<li>In other words, we'll want to first transform a hyperparameter to change its range of values before sampling</li>\n<li>Specifically, we'll want to randomly sample hyperparameters uniformly on a logarithmic scale</li>\n<li>When tuning a hyperparameter, we'll typically want to do this if we care about testing many hyperparameters in only a certain small region</li>\n<li>For example, we may decide to randomly sample <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>β</mi><mi>v</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\beta_{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> uniformly on a linear scale</li>\n<li>In this scenario, we would be only using <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>90</mn></mrow><annotation encoding=\"application/x-tex\">90</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">9</span><span class=\"mord\">0</span></span></span></span>% of resources to search for the values of a hyperparameter <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>β</mi><mi>v</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\beta_{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> between <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>0.1</mn></mrow><annotation encoding=\"application/x-tex\">0.1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">1</span></span></span></span> and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span></li>\n</ul>\n<p><img src=\"/623e0627349e49f486c502e44f180b95/linear_tuning.svg\" alt=\"linearscale\"></p>\n<ul>\n<li>However, we may want to use more resources to search for the values between <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span> and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>0.1</mn></mrow><annotation encoding=\"application/x-tex\">0.1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">1</span></span></span></span></li>\n<li>Therefore, we may want to randomly sample <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>β</mi><mi>v</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\beta_{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> uniformly on a logarithmic scale</li>\n</ul>\n<p><img src=\"/878c4ac196243ff81144e55ede2e2f9b/log_tuning.svg\" alt=\"logscale\"></p>\n<h3>Re-evaluating Hyperparameters Occasionally</h3>\n<ul>\n<li>Our data is always changing</li>\n<li>That means insights we take from some data can change over time as well</li>\n<li>Therefore, we should always be re-evaluating our hyperparameters to update our model</li>\n<li>\n<p>There are two different methods used for re-evaluating hyperparameters:</p>\n<ol>\n<li>\n<p>Babysitting one model</p>\n<ul>\n<li>This method refers to tuning hyperparameters of one model and observing how the accuracy of our test set changes over time</li>\n<li>If we notice a high enough accuracy for a set of hyperparameters on a certain day, then we should use those</li>\n<li>Usually we do this if we don't have enough computational resources</li>\n</ul>\n</li>\n<li>\n<p>Training many models in parallel</p>\n<ul>\n<li>This method refers to tuning hyperparameters of many models in parallel and observing how the accuracy of a test set changes over time for each model</li>\n<li>If we notice a high enough accuracy for a set of hyperparameters of one model on a certain day, then we should select that set of hyperparameters</li>\n<li>Usually we do this if we have an abundance of computational resources</li>\n</ul>\n</li>\n</ol>\n</li>\n<li>Typically, we prefer the second approach if we have enough computational resources</li>\n<li>If we're not fortunate enough to have an abundance of CPUs and GPUs, then we should use the babysitting method</li>\n</ul>\n<hr>\n<h3>tldr</h3>\n<ul>\n<li>When tuning hyperparameters, we should test many possible values using random sampling from a hyperparameter space</li>\n<li>We should not test many possible values using grid search</li>\n<li>After training, we should focus on a smaller range of hyperparameters that minimize the cost function</li>\n<li>By default, we randomly sample hyperparameters uniformly on a linear scale</li>\n<li>We may want to randomly sample hyperparameters uniformly on a logarithmic scale</li>\n<li>Typically, we prefer to tune hyperparameters of many models in parallel if we have enough computational resource</li>\n<li>If we don't have enough resources, then we should monitor the accuracy of one model over time</li>\n</ul>\n<hr>\n<h3>References</h3>\n<ul>\n<li><a href=\"https://www.youtube.com/watch?v=AXDByU3D1hA&#x26;list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc&#x26;index=24\" target=\"_blank\" rel=\"nofollow\">Tuning Process</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=cSoK_6Rkbfg&#x26;list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc&#x26;index=25\" target=\"_blank\" rel=\"nofollow\">Using an Appropriate Scale</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=wKkcBPp3F1Y&#x26;list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc&#x26;index=26\" target=\"_blank\" rel=\"nofollow\">Hyperparameter Tuning in Practice</a></li>\n</ul>"}},"pageContext":{"slug":"ml/deep_learning/tuning","previousSlug":"ml/deep_learning/learning_decay","nextSlug":"ml/deep_learning/batch_norm","previousTitle":"Learning Rate Decay","nextTitle":"Batch Normalization"}},"staticQueryHashes":[]}