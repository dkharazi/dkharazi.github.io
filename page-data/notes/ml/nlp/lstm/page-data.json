{"componentChunkName":"component---src-templates-entry-js","path":"/notes/ml/nlp/lstm","result":{"data":{"markdownRemark":{"frontmatter":{"title":"Long Short-Term Memory"},"html":"<h3>Describing the LSTM Model</h3>\n<ul>\n<li>An LSTM is a type of RNN</li>\n<li>An LSTM mitigates the issue with vanishing and exploding gradients by ensuring back-propagated gradients are unchanged</li>\n<li>It is designed to handle entire sequences of data by learning when to remember and forget previous information</li>\n<li>\n<p>An LSTM consists of <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>4</mn></mrow><annotation encoding=\"application/x-tex\">4</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">4</span></span></span></span> components:</p>\n<ul>\n<li>A cell state (sometimes called memory)</li>\n<li>A forget gate</li>\n<li>An input gate</li>\n<li>An output gate</li>\n</ul>\n</li>\n</ul>\n<h3>Summarizing the Four Components of an LSTM</h3>\n<ul>\n<li>\n<p>Cell states</p>\n<ul>\n<li>They represent previous information</li>\n<li>Roughly, the hidden state represents <em>short-term memory</em>, whereas the cell state represents <em>long-term memory</em></li>\n<li>More accurately, the <strong>hidden state</strong> is used for making predictions, whereas the <strong>cell state</strong> is used as memory</li>\n</ul>\n</li>\n<li>\n<p>Forget gates</p>\n<ul>\n<li>They decide what is relevant to keep from previous information</li>\n<li>Specifically, they represent the process of filtering out any unrelated information from the previous information</li>\n</ul>\n</li>\n<li>\n<p>Input gates</p>\n<ul>\n<li>They decide what is relevant to add from the new information</li>\n<li>Specifically, they represent the process of computing new information based on current and previous information</li>\n</ul>\n</li>\n<li>\n<p>Output gates</p>\n<ul>\n<li>They decide what the next hidden state should be</li>\n<li>Specifically, they represent the process of outputting the filtered and calculated current information</li>\n</ul>\n</li>\n</ul>\n<h3>Illustrating the Components of an LSTM</h3>\n<ul>\n<li>Suppose we received a phone call from a friend</li>\n<li>When our phone rings, we may be thinking about any number of thoughts already</li>\n<li>These thoughts could be related or unrelated to our friend</li>\n<li>This state of thinking represents our <strong>cell state</strong></li>\n<li>In other words, the cell state represents our previous thoughts</li>\n<li>When we answer the call, we'll put aside any unrelated thoughts while retaining anything we meant to talk to our friend about</li>\n<li>This process represents the <strong>forget gate</strong></li>\n<li>In other words, the forget gate represents filtering out only relevant thoughts at the beginning of the conversation</li>\n<li>As the conversation progresses, we'll take in and interpret all of the new information from our friend</li>\n<li>As our friend speaks, we'll be thinking of an appropriate response</li>\n<li>This process represents the <strong>input gate</strong></li>\n<li>In other words, the input gate represents thinking of a response</li>\n<li>Once we decide what to say next, we'll begin to speak to our friend</li>\n<li>This process represents the <strong>output gate</strong></li>\n<li>In other words, the output gate represents our actual response</li>\n</ul>\n<h3>Defining the Architecture of an LSTM</h3>\n<ul>\n<li>The general architecture for an LSTM is depicted below:</li>\n</ul>\n<p><img src=\"/bfbd63d7d07e946c1017c5049b1e8201/lstmcell.svg\" alt=\"lstmcell\"></p>\n<ul>\n<li>\n<p>Again, the general architecture consists of the <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>4</mn></mrow><annotation encoding=\"application/x-tex\">4</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">4</span></span></span></span> components:</p>\n<ul>\n<li>A cell state</li>\n<li>A forget gate</li>\n<li>An input gate</li>\n<li>An output gate</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/c22d93721e1e0e4161200efa97d37ff7/lstmcomponents.svg\" alt=\"lstmcomponents\"></p>\n<h3>Illustrating the Use of Gates in an LSTM</h3>\n<ul>\n<li>\n<p>Here, the <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>tanh</mi><mo>⁡</mo></mrow><annotation encoding=\"application/x-tex\">\\tanh</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mop\">tanh</span></span></span></span> activation function is used to regulate (or standardize) values flowing through the network</p>\n<ul>\n<li>Specifically, it squishes values between <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo>−</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">-1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord\">−</span><span class=\"mord\">1</span></span></span></span> and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span></li>\n<li>The frequent use of <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>tanh</mi><mo>⁡</mo></mrow><annotation encoding=\"application/x-tex\">\\tanh</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mop\">tanh</span></span></span></span> functions throughout the cell helps reduce the problem with vanishing and exploding gradients</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/f334aa1289c36652d254cba6aa319a74/lstmnotanh.gif\" alt=\"lstmcell\"></p>\n<p><img src=\"/e1f53149d1f9631c1af50805dbb4e3dc/lstmwithtanh.gif\" alt=\"lstmcell\"></p>\n<ul>\n<li>A vanilla RNN uses much fewer computational resources compared to an LSTM and a GRU</li>\n<li>\n<p>The cell state acts as a pathway used for transporting relevant information between cells</p>\n<ul>\n<li>It can be thought of as the memory between previous cells</li>\n<li>Implying, it can carry relevant information from previous cells</li>\n<li>This is where its <em>long-term memory</em> comes from</li>\n</ul>\n</li>\n<li>Gates learn what information is relevant to keep or forget at different points in the network</li>\n<li>\n<p>Specifically, gates are used for</p>\n<ul>\n<li>Adding information to the cell state of previous cells</li>\n<li>Removing information from the cell state of previous cells</li>\n</ul>\n</li>\n<li>\n<p>A gate contains a <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>σ</mi></mrow><annotation encoding=\"application/x-tex\">\\sigma</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span></span></span></span> activation functions</p>\n<ul>\n<li>Sigmoid functions squish values between <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span> and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span></li>\n<li>This function is useful for keeping and forgetting data</li>\n<li>If the output is <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span>, then values will be <em>forgotten</em></li>\n<li>Conversely, if the output is <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span>, then values are kept</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/e1052fedd6164f92754821e291bbb766/lstmsigmoid.gif\" alt=\"lstmsigmoid\"></p>\n<h3>Illustrating the Forget Gate in an LSTM</h3>\n<ul>\n<li>\n<p>A forget gate decides what information should be kept or forgotten</p>\n<ul>\n<li>Here, a sigmoid function receives information from the previous hidden state and information from the current input</li>\n<li>The output values are between <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span> and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span></li>\n<li>Meaning, values closer to <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span> are forgotten, whereas values closer to <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span> are kept</li>\n<li>This is where its <em>short-term memory</em> comes from</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/6c7bd0888f84cfd7d5cf3bc03e9cdbfd/lstmforget.gif\" alt=\"lstmforget\"></p>\n<h3>Illustrating the Input Gate in an LSTM</h3>\n<ul>\n<li>\n<p>The input gate is used for updating the cell state</p>\n<ul>\n<li>Here, a sigmoid function receives information from the previous hidden state and information from the current input</li>\n<li>The output values are between <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span> and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span></li>\n<li>If the output is <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span>, then values will be <em>forgotten</em></li>\n<li>Conversely, if the output is <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span>, then values are kept</li>\n<li>Essentially, the sigmoid function determines which information to keep from the output of the <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>tanh</mi><mo>⁡</mo></mrow><annotation encoding=\"application/x-tex\">\\tanh</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mop\">tanh</span></span></span></span> function</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/1167da9a6386278cda018b3da01f006d/lstminput.gif\" alt=\"lstminput\"></p>\n<h3>Illustrating the Cell State Update in an LSTM</h3>\n<ul>\n<li>\n<p>The cell state is updated based on the output of the forget gate and the output of the input gate</p>\n<ul>\n<li>The forget gate determines whether values should be forgotten</li>\n<li>The input gate determines what values should be updated</li>\n<li>The forget gate can forget values from the cell state if the output is <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span></li>\n<li>Similarly, the input gate can forget values from the current input if the output is <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span></li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/726bf910e01dea258ccd6bc7ad96e5fb/lstmcell.gif\" alt=\"lstmcell\"></p>\n<h3>Illustrating the Output Gate in an LSTM</h3>\n<ul>\n<li>\n<p>The output gate decides what the next hidden state should be</p>\n<ul>\n<li>Recall, a hidden state contains information from previous inputs</li>\n<li>The hidden state is also used for making predictions</li>\n<li>Here, a <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>σ</mi></mrow><annotation encoding=\"application/x-tex\">\\sigma</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span></span></span></span> function receives information from the previous hidden state and the current input</li>\n<li>Then, a <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>tanh</mi><mo>⁡</mo></mrow><annotation encoding=\"application/x-tex\">\\tanh</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mop\">tanh</span></span></span></span> function receives information from the newly modified cell state</li>\n<li>The output from the <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>tanh</mi><mo>⁡</mo></mrow><annotation encoding=\"application/x-tex\">\\tanh</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mop\">tanh</span></span></span></span> and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>σ</mi></mrow><annotation encoding=\"application/x-tex\">\\sigma</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span></span></span></span> functions are multiplied to decide what information the hidden state should carry</li>\n<li>The output of this multiplication becomes the hidden state</li>\n<li>The new cell state and the new hidden is then carried over to the next time cell</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/4bd9fc13ff4cc2f65473a35bd1112933/lstmoutput.gif\" alt=\"lstmcell\"></p>\n<h3>Applications of an LSTM</h3>\n<ul>\n<li>Next-character predictions</li>\n<li>Chatbots</li>\n<li>Image captioning</li>\n<li>Music composition</li>\n<li>Speech recognition</li>\n</ul>\n<h3>References</h3>\n<ul>\n<li><a href=\"http://cs224d.stanford.edu/lectures/\" target=\"_blank\" rel=\"nofollow\">Stanford Deep Learning Lectures</a></li>\n<li><a href=\"http://cs224d.stanford.edu/lectures/CS224d-Lecture9.pdf\" target=\"_blank\" rel=\"nofollow\">Stanford Lecture about LSTMs</a></li>\n<li><a href=\"https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be\" target=\"_blank\" rel=\"nofollow\">Article Describing the Components of LSTMs</a></li>\n<li><a href=\"https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\" target=\"_blank\" rel=\"nofollow\">Illustrating the Architecture of LSTMs</a></li>\n<li><a href=\"https://arxiv.org/pdf/1412.3555.pdf\" target=\"_blank\" rel=\"nofollow\">Paper about an LSTM</a></li>\n</ul>"}},"pageContext":{"slug":"ml/nlp/lstm","previousSlug":"ml/nlp/gru","nextSlug":"ml/nlp/siamese","previousTitle":"Gated Recurrent Units","nextTitle":"Siamese Networks"}},"staticQueryHashes":[]}