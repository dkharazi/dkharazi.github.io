{"componentChunkName":"component---src-templates-entry-js","path":"/notes/ml/parametric_regression/mle","result":{"data":{"markdownRemark":{"frontmatter":{"title":"Maximum Likelihood Estimation"},"html":"<h3>Describing Maximum Likelihood Estimation</h3>\n<ul>\n<li>Continuous random variables have a probability density function (also known as a likelihood function)</li>\n<li>Probability density functions take in sample data as input and return likelihoods as output</li>\n<li>Likelihoods represent the chance (or the joint probability) of observing the data given the parameters of a model, assuming the data is represented by the distribution we chose</li>\n<li>Maximum likelihood estimation is a method that determines values for the parameters of a model</li>\n<li>The parameter values are found such that they maximize the likelihood that the process (or random variable) described by the model produced the data that were actually observed</li>\n<li>The optimal parameters that maximize the likelihood are called the maximum likelihood estimates</li>\n<li>MLE can be seen as a special case of the MAP estimation, where we assume the parameters have a prior that is uniformly distributed</li>\n</ul>\n<h3>An Example of the MLE</h3>\n<ul>\n<li>Technically speaking, maximum likelihood estimation is a method of estimating the parameters of a distribution by finding the parameter values that maximize the likelihood of observing the data given our parameters</li>\n<li>For example, let's say we want to know the expected value of a normally-distributed random variable <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">X</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span></span></span></span></li>\n<li>Then, we would use MLE to determine the estimate of our <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>μ</mi></mrow><annotation encoding=\"application/x-tex\">\\mu</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">μ</span></span></span></span> parameter, which equals the <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mtext>E</mtext><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\text{E}(X)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">E</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mclose\">)</span></span></span></span></li>\n<li>In other words, we would use maximum likelihood estimation to find the value of the parameter that gives us the mode of our sample data</li>\n<li>In this scenario, our maximum likelihood estimate is the parameter that gives us the mode</li>\n</ul>\n<h3>Defining the Steps of the MLE Algorithm</h3>\n<ol>\n<li>Receive some data</li>\n<li>\n<p>Determine the distributional family of the data</p>\n<ul>\n<li>We can do this using plots, such as histograms</li>\n</ul>\n</li>\n<li>\n<p>Determine the parameters for our distribution that is most likely responsible for creating our data</p>\n<ul>\n<li>We use maximum likelihood estimation to find the values of our parameters, which results in the curve that best fits the data</li>\n<li>Each parameter typically has a formula for the MLE</li>\n<li>\n<p>For example, we have sample data and we believe that our sample data is normally distributed</p>\n<ul>\n<li>So, we would want to know how exactly that normal distribution looks in terms of our data</li>\n<li>This means we are interested in how the parameters should be adjusted to find the exact normal curve that has given us our sample data</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<h3>Generalizing the Algorithm</h3>\n<ol>\n<li>Find the probability density function that seems to fit our data</li>\n<li>Take the log of the likehood function (or the pdf)</li>\n<li>Take the partial derivative of the function with respect to each parameter</li>\n</ol>\n<h3>Does MLE Always Work?</h3>\n<ul>\n<li>No, since random variables from the real world take on more complicated functions, rather than the standard probability density functions (e.g. normal distribution) we're used to seeing</li>\n<li>In other words, our data generating process can't always be reduced to a straight-forward formula</li>\n<li>In these cases, we can use more specialized methods to find numerical solutions for these parameter estimates</li>\n<li>These methods typically include iterative methods, such as Expectation-Maximization algorithms or Gradient Descent</li>\n</ul>\n<h3>Why Likelihoods Aren't Probabilities?</h3>\n<ul>\n<li>This is mostly just statisticians being pedantic</li>\n<li>Most people tend to use probability and likelihood interchangeably, but statsticians distinguish between the two (for good reason)</li>\n<li>Probabilities are used to describe the chance associated with discrete random variables</li>\n<li>Likelihoods are used to describe the chance associated with continuous random variables</li>\n</ul>\n<h3>References</h3>\n<ul>\n<li><a href=\"https://towardsdatascience.com/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1\" target=\"_blank\" rel=\"nofollow\">MLE Introduction Article</a></li>\n<li><a href=\"https://towardsdatascience.com/a-gentle-introduction-to-maximum-likelihood-estimation-9fbff27ea12f\" target=\"_blank\" rel=\"nofollow\">Frequentist MLE Article</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=XepXtl9YKwc\" target=\"_blank\" rel=\"nofollow\">StatQuest Maximum Likelihood Video</a></li>\n</ul>"}},"pageContext":{"slug":"ml/parametric_regression/mle","previousSlug":null,"nextSlug":"ml/parametric_regression/ols","previousTitle":null,"nextTitle":"Ordinary Least Squares Estimation"}},"staticQueryHashes":[]}