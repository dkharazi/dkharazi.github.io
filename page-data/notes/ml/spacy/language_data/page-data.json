{"componentChunkName":"component---src-templates-entry-js","path":"/notes/ml/spacy/language_data","result":{"data":{"markdownRemark":{"frontmatter":{"title":"Language Data"},"html":"<h3>Introducing Language Data</h3>\n<ul>\n<li>There are some rules that are generalized across languages</li>\n<li>Most languages are full of special rules and exceptions</li>\n<li>These exceptions are hard-coded and organized in simple Python files</li>\n<li>Specifically, these hard-coded files are called language data in spacy</li>\n<li>\n<p>There are two types of language data in spacy:</p>\n<ul>\n<li>\n<p>Shared language data</p>\n<ul>\n<li>This refers to rules that are generalized across languages</li>\n<li>E.g. rules for basic punctuation, emojis, and norms for equivalent tokens with different spellings, such as <code class=\"language-text\">&quot;</code> and <code class=\"language-text\">‚Äù</code></li>\n</ul>\n</li>\n<li>\n<p>Individual language data</p>\n<ul>\n<li>This refers to rules that are specific to a particular language</li>\n<li>It also takes care of putting together all the components of the <code class=\"language-text\">Language</code> subclass</li>\n<li>E.g. <code class=\"language-text\">English</code> or <code class=\"language-text\">German</code></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/ef63e6a58b7ec47c073fb59857a76e5f/language_data.svg\" alt=\"LanguageData\"></p>\n<h3>Components of a Pipeline</h3>\n<ul>\n<li>\n<p><code class=\"language-text\">Stop Words:</code> List of most common words of a language that are often useful to filter our</p>\n<ul>\n<li>E.g. <em>and</em>, <em>I</em>, etc.</li>\n<li>Matching tokens will return <code class=\"language-text\">True</code> for <code class=\"language-text\">is_stop</code></li>\n</ul>\n</li>\n<li>\n<p><code class=\"language-text\">Tokenizer Exceptions:</code> Special-case rules for the tokenizer</p>\n<ul>\n<li>I.e. contractions and abbreviations</li>\n<li>E.g. <em>can't</em>, <em>U.K.</em>, etc.</li>\n</ul>\n</li>\n<li>\n<p><code class=\"language-text\">Norm Exceptions:</code> Special-case rules for normalizing tokens</p>\n<ul>\n<li>Used to improve the model's predictions</li>\n<li>E.g. American versus British spelling</li>\n</ul>\n</li>\n<li>\n<p><code class=\"language-text\">Punctuation Rules:</code> Regular expressions for splitting tokens</p>\n<ul>\n<li>This includes rules for prefixes, suffices, and infixes</li>\n<li>E.g. punctuation, special characters, and emojis</li>\n</ul>\n</li>\n<li>\n<p><code class=\"language-text\">Character Classes:</code> Character classes to be used in regular expressions</p>\n<ul>\n<li>E.g. latin characters, quotes, hyphens, or icons</li>\n</ul>\n</li>\n<li>\n<p><code class=\"language-text\">Lexical Attributes:</code> Custom functions for setting lexical attributes on tokens</p>\n<ul>\n<li>E.g. <code class=\"language-text\">like_num</code> which includes language-specific words</li>\n<li>E.g. <em>ten</em>, <em>hundred</em>, etc.</li>\n</ul>\n</li>\n<li>\n<p><code class=\"language-text\">Syntax Iterators:</code> Functions that compute views of a <code class=\"language-text\">Doc</code> object based on its syntax</p>\n<ul>\n<li>At the moment, only used for noun chunks</li>\n</ul>\n</li>\n<li><code class=\"language-text\">Tag Map:</code> Dictionary mapping strings in our tag set to <a href=\"https://universaldependencies.org/u/pos/all.html\" target=\"_blank\" rel=\"nofollow\">Universal Dependencies</a> tags</li>\n<li>\n<p><code class=\"language-text\">Morph Rules:</code> Exception rules for morphological analysis of irregular words</p>\n<ul>\n<li>E.g. personal pronouns, etc.</li>\n</ul>\n</li>\n<li>\n<p><code class=\"language-text\">Lemmatizer:</code> Lemmatization rules or a lookup-based lemmatization table to assign base forms</p>\n<ul>\n<li>E.g. <em>be</em> for <em>was</em></li>\n</ul>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>Variable</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code class=\"language-text\">STOP_WORDS</code></td>\n<td>set</td>\n<td>Individual words</td>\n</tr>\n<tr>\n<td><code class=\"language-text\">TOKENIZER_EXCEPTIONS</code></td>\n<td>dict</td>\n<td>Keyed by strings mapped to list of one dict per token with token attributes</td>\n</tr>\n<tr>\n<td><code class=\"language-text\">TOKEN_MATCH</code></td>\n<td>regex</td>\n<td>Regexes to match complex tokens, e.g. URLS</td>\n</tr>\n<tr>\n<td><code class=\"language-text\">NORM_EXCEPTIONS</code></td>\n<td>dict</td>\n<td>Keyed by strings, mapped to their norms</td>\n</tr>\n<tr>\n<td><code class=\"language-text\">TOKENIZER_PREFIXES</code></td>\n<td>list</td>\n<td>Strings or regexes usually not customized</td>\n</tr>\n<tr>\n<td><code class=\"language-text\">TOKENIZER_SUFFIXES</code></td>\n<td>list</td>\n<td>Strings or regexes usually not customized</td>\n</tr>\n<tr>\n<td><code class=\"language-text\">TOKENIZER_INFIXES</code></td>\n<td>list</td>\n<td>Strings or regexes usually not customizes</td>\n</tr>\n<tr>\n<td><code class=\"language-text\">LEX_ATTRS</code></td>\n<td>dict</td>\n<td>Attribute ID mapped to function</td>\n</tr>\n<tr>\n<td><code class=\"language-text\">SYNTAX_ITERATORS</code></td>\n<td>dict</td>\n<td>Iterator ID mapped to function</td>\n</tr>\n<tr>\n<td><code class=\"language-text\">TAG_MAP</code></td>\n<td>dict</td>\n<td>Keyed by strings mapped to Universal Dependencies tags</td>\n</tr>\n<tr>\n<td><code class=\"language-text\">MORPH_RULE</code></td>\n<td>dict</td>\n<td>Keyed by strings mapped to a dict of their morphological features</td>\n</tr>\n</tbody>\n</table>\n<h3>References</h3>\n<ul>\n<li><a href=\"https://spacy.io/usage/adding-languages#language-data\" target=\"_blank\" rel=\"nofollow\">Description of Language Data</a></li>\n</ul>"}},"pageContext":{"slug":"ml/spacy/language_data","previousSlug":"ml/spacy/pipeline","nextSlug":"ml/spacy/architecture","previousTitle":"Spacy Pipeline","nextTitle":"Spacy Architecture"}},"staticQueryHashes":[]}