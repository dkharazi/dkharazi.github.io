{"componentChunkName":"component---src-templates-entry-js","path":"/notes/ml/spacy/tokenization","result":{"data":{"markdownRemark":{"frontmatter":{"title":"Tokenization"},"html":"<h3>Describing Tokenization</h3>\n<ul>\n<li>Tokenization is the task of splitting input text into meaningful segments called <em>tokens</em></li>\n<li>The input to the tokenizer is a unicode text</li>\n<li>The output is a <code class=\"language-text\">Doc</code> object</li>\n<li>To construct a <code class=\"language-text\">Doc</code> object, we need a <code class=\"language-text\">Vocab</code> objecy, a sequence of stringed words, and optionally a sequence of booleaned spaces</li>\n</ul>\n<h3>The Algorithm for Tokenization</h3>\n<ol>\n<li>The <code class=\"language-text\">Tokenizer</code> receives some raw text.</li>\n<li>Iterate over whitespace-separated substrings.</li>\n<li>Check whether we have an explicitly defined rule for this substring. If we do, then we should use the rule and skip the remaining steps.</li>\n<li>Otherwise, try consuming a prefix. Return to step 2 if we consume a prefix.</li>\n<li>Otherwise, try consuming a suffix. Return to step 2 if we consume a suffix.</li>\n<li>Otherwise, try consuming a special case (e.g. symbol). Return to step 2 if we consume a special case.</li>\n<li>Otherwise, try consuming infixes (e.g. hyphens) and split the substring into tokens on all infixes.</li>\n<li>Once we get to this step without any consumption or discovered rule, then handle the substring as a single token.</li>\n</ol>\n<p><img src=\"/57e618bd79d933c4ccd308b5739062d6/tokenization.svg\" alt=\"Tokenization\"></p>\n<h3>Spacy Pseudocode for Tokenization</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">tokenizer_pseudo_code<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> special_cases<span class=\"token punctuation\">,</span> prefix_search<span class=\"token punctuation\">,</span>\n                      suffix_search<span class=\"token punctuation\">,</span> infix_finditer<span class=\"token punctuation\">,</span> token_match<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    tokens <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">for</span> substring <span class=\"token keyword\">in</span> text<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        suffixes <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">while</span> substring<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>prefix_search<span class=\"token punctuation\">(</span>substring<span class=\"token punctuation\">)</span> <span class=\"token keyword\">or</span> \n                   suffix_search<span class=\"token punctuation\">(</span>substring<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">if</span> substring <span class=\"token keyword\">in</span> special_cases<span class=\"token punctuation\">:</span>\n                    tokens<span class=\"token punctuation\">.</span>extend<span class=\"token punctuation\">(</span>special_cases<span class=\"token punctuation\">[</span>substring<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n                    substring <span class=\"token operator\">=</span> <span class=\"token string\">''</span>\n                    <span class=\"token keyword\">break</span>\n                <span class=\"token keyword\">if</span> prefix_search<span class=\"token punctuation\">(</span>substring<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                    split <span class=\"token operator\">=</span> prefix_search<span class=\"token punctuation\">(</span>substring<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>end<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n                    tokens<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>substring<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>split<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n                    substring <span class=\"token operator\">=</span> substring<span class=\"token punctuation\">[</span>split<span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span>\n                    <span class=\"token keyword\">if</span> substring <span class=\"token keyword\">in</span> special_cases<span class=\"token punctuation\">:</span>\n                        <span class=\"token keyword\">continue</span>\n                <span class=\"token keyword\">if</span> suffix_search<span class=\"token punctuation\">(</span>substring<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                    split <span class=\"token operator\">=</span> suffix_search<span class=\"token punctuation\">(</span>substring<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>start<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n                    suffixes<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>substring<span class=\"token punctuation\">[</span>split<span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n                    substring <span class=\"token operator\">=</span> substring<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>split<span class=\"token punctuation\">]</span>\n            <span class=\"token keyword\">if</span> substring <span class=\"token keyword\">in</span> special_cases<span class=\"token punctuation\">:</span>\n                tokens<span class=\"token punctuation\">.</span>extend<span class=\"token punctuation\">(</span>special_cases<span class=\"token punctuation\">[</span>substring<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n                substring <span class=\"token operator\">=</span> <span class=\"token string\">''</span>\n            <span class=\"token keyword\">elif</span> token_match<span class=\"token punctuation\">(</span>substring<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                tokens<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>substring<span class=\"token punctuation\">)</span>\n                substring <span class=\"token operator\">=</span> <span class=\"token string\">''</span>\n            <span class=\"token keyword\">elif</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>infix_finditer<span class=\"token punctuation\">(</span>substring<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                infixes <span class=\"token operator\">=</span> infix_finditer<span class=\"token punctuation\">(</span>substring<span class=\"token punctuation\">)</span>\n                offset <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n                <span class=\"token keyword\">for</span> match <span class=\"token keyword\">in</span> infixes<span class=\"token punctuation\">:</span>\n                    tokens<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>substring<span class=\"token punctuation\">[</span>offset<span class=\"token punctuation\">:</span>match<span class=\"token punctuation\">.</span>start<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n                    match_interval <span class=\"token operator\">=</span> match<span class=\"token punctuation\">.</span>start<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>match<span class=\"token punctuation\">.</span>end<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n                    tokens<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>substring<span class=\"token punctuation\">[</span>match_interval<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n                    offset <span class=\"token operator\">=</span> match<span class=\"token punctuation\">.</span>end<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n                <span class=\"token keyword\">if</span> substring<span class=\"token punctuation\">[</span>offset<span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n                    tokens<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>substring<span class=\"token punctuation\">[</span>offset<span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n                substring <span class=\"token operator\">=</span> <span class=\"token string\">''</span>\n            <span class=\"token keyword\">elif</span> substring<span class=\"token punctuation\">:</span>\n                tokens<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>substring<span class=\"token punctuation\">)</span>\n                substring <span class=\"token operator\">=</span> <span class=\"token string\">''</span>\n        tokens<span class=\"token punctuation\">.</span>extend<span class=\"token punctuation\">(</span><span class=\"token builtin\">reversed</span><span class=\"token punctuation\">(</span>suffixes<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> tokens</code></pre></div>\n<h3>References</h3>\n<ul>\n<li><a href=\"https://spacy.io/usage/linguistic-features#tokenization\" target=\"_blank\" rel=\"nofollow\">Tokenization in Spacy</a></li>\n<li><a href=\"https://spacy.io/api/tokenizer\" target=\"_blank\" rel=\"nofollow\">Tokenizer Class</a></li>\n</ul>"}},"pageContext":{"slug":"ml/spacy/tokenization","previousSlug":"ml/spacy/architecture","nextSlug":"ml/spacy/pos","previousTitle":"Spacy Architecture","nextTitle":"Part-of-Speech Tagging"}},"staticQueryHashes":[]}